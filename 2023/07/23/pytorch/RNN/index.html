<!DOCTYPE html>
<html lang="zh-CN">
    <head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/#5.7.10'>
  <meta name="generator" content="Hexo 5.4.2">
  <meta name="Volantis" content="5.7.10">
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
  <link rel="canonical" href="http://breadwinners.top/2023/07/23/pytorch/rnn/"/>
  <!-- 渲染优化 -->
    <meta http-equiv='x-dns-prefetch-control' content='on' />
      <link rel='dns-prefetch' href='https://unpkg.com'>
      <link rel="preconnect" href="https://unpkg.com" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Content-Security-Policy" content=" default-src 'self' https:; block-all-mixed-content; base-uri 'self' https:; form-action 'self' https:; worker-src 'self' https:; connect-src 'self' https: *; img-src 'self' data: https: *; media-src 'self' https: *; font-src 'self' data: https: *; frame-src 'self' https: *; manifest-src 'self' https: *; child-src https:; script-src 'self' https: 'unsafe-inline' *; style-src 'self' https: 'unsafe-inline' *; ">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style">
  <meta content="telephone=no" name="format-detection">
  <!-- import head_begin begin -->
  <!-- import head_begin end -->
  <!-- Custom Files headBegin begin-->
  
  <!-- Custom Files headBegin end-->
    <link rel="shortcut icon" type='image/x-icon' href="https://gcore.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicon.ico">
  <link rel="preload" href="/css/style.css" as="style">
  <link rel="preload" href="https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/VarelaRound/VarelaRound-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous">
<link rel="preload" href="https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/UbuntuMono/UbuntuMono-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous">

  <!-- feed -->
  <!-- 页面元数据 -->
  <title>RNN - 怒涛卷霜雪  天堑无涯</title>
  <meta name="keywords" content="rnn,null">
  <meta desc name="description" content="test description - 吴涛 - 怒涛卷霜雪  天堑无涯">
  
<meta property="og:type" content="article">
<meta property="og:title" content="RNN">
<meta property="og:url" content="http://breadwinners.top/2023/07/23/pytorch/RNN/index.html">
<meta property="og:site_name" content="怒涛卷霜雪  天堑无涯">
<meta property="og:description" content="1 什么是RNN？RNN是循环神经网络（Recurrent Neural Network）的缩写。它是一种神经网络结构，可以处理序列数据，例如时间序列数据或自然语言文本数据。相比于传统的前馈神经网络，RNN可以利用当前的输入和之前的状态来决定当前的输出，因此它可以捕捉到序列数据中的时间依赖关系。 在RNN中，每个时间步都有一个隐藏状态（hidden state），这个隐藏状态可以捕捉到之前时间步的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
<meta property="article:published_time" content="2023-07-22T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-01T01:46:54.757Z">
<meta property="article:author" content="吴涛">
<meta property="article:tag" content="rnn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
  <style>
    /* 首屏样式 */
    #safearea {
  display: none;
}
:root {
  --color-site-body: #f4f4f4;
  --color-site-bg: #f4f4f4;
  --color-site-inner: #fff;
  --color-site-footer: #666;
  --color-card: #fff;
  --color-text: #444;
  --color-block: #f6f6f6;
  --color-inlinecode: #c74f00;
  --color-codeblock: #fff7ea;
  --color-h1: #3a3a3a;
  --color-h2: #3a3a3a;
  --color-h3: #333;
  --color-h4: #444;
  --color-h5: #555;
  --color-h6: #666;
  --color-p: #444;
  --color-list: #666;
  --color-list-hl: #30ad91;
  --color-meta: #888;
  --color-read-bkg: #e0d8c8;
  --color-read-post: #f8f1e2;
  --color-copyright-bkg: #f5f5f5;
}
* {
  box-sizing: border-box;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  outline: none;
  margin: 0;
  padding: 0;
}
*::-webkit-scrollbar {
  height: 4px;
  width: 4px;
}
*::-webkit-scrollbar-track-piece {
  background: transparent;
}
*::-webkit-scrollbar-thumb {
  background: #3dd9b6;
  cursor: pointer;
  border-radius: 2px;
  -webkit-border-radius: 2px;
}
*::-webkit-scrollbar-thumb:hover {
  background: #ff5722;
}
html {
  color: var(--color-text);
  width: 100%;
  height: 100%;
  font-family: UbuntuMono, "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Menlo, Monaco, monospace, sans-serif;
  font-size: 16px;
}
html >::-webkit-scrollbar {
  height: 4px;
  width: 4px;
}
html >::-webkit-scrollbar-track-piece {
  background: transparent;
}
html >::-webkit-scrollbar-thumb {
  background: #54b5a0 linear-gradient(45deg, rgba(255,255,255,0.4) 25%, transparent 25%, transparent 50%, rgba(255,255,255,0.4) 50%, rgba(255,255,255,0.4) 75%, transparent 75%, transparent);
  cursor: pointer;
  border-radius: 2px;
  -webkit-border-radius: 2px;
}
html >::-webkit-scrollbar-thumb:hover {
  background: #54b5a0 linear-gradient(45deg, rgba(255,255,255,0.4) 25%, transparent 25%, transparent 50%, rgba(255,255,255,0.4) 50%, rgba(255,255,255,0.4) 75%, transparent 75%, transparent);
}
body {
  background-color: var(--color-site-body);
  text-rendering: optimizelegibility;
  -webkit-tap-highlight-color: rgba(0,0,0,0);
  line-height: 1.6;
  -webkit-text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
}
body.modal-active {
  overflow: hidden;
}
@media screen and (max-width: 680px) {
  body.modal-active {
    position: fixed;
    top: 0;
    right: 0;
    bottom: 0;
    left: 0;
  }
}
a {
  color: #2092ec;
  cursor: pointer;
  text-decoration: none;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
a:hover {
  color: #ff5722;
}
a:active,
a:hover {
  outline: 0;
}
ul,
ol {
  padding-left: 0;
}
ul li,
ol li {
  list-style: none;
}
header {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
}
img {
  border: 0;
  background: none;
  max-width: 100%;
}
svg:not(:root) {
  overflow: hidden;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  -webkit-box-sizing: content-box;
  -moz-box-sizing: content-box;
  height: 0;
  border: 0;
  border-radius: 1px;
  -webkit-border-radius: 1px;
  border-bottom: 1px solid rgba(68,68,68,0.1);
}
button,
input {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
  text-transform: none;
  -webkit-appearance: button;
  cursor: pointer;
}
@supports (backdrop-filter: blur(20px)) {
  .blur {
    background: rgba(255,255,255,0.9) !important;
    backdrop-filter: saturate(200%) blur(20px);
  }
}
.shadow {
  box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
  -webkit-box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
}
.shadow.floatable {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.shadow.floatable:hover {
  box-shadow: 0 2px 4px 0px rgba(0,0,0,0.1), 0 4px 8px 0px rgba(0,0,0,0.1), 0 8px 16px 0px rgba(0,0,0,0.1);
  -webkit-box-shadow: 0 2px 4px 0px rgba(0,0,0,0.1), 0 4px 8px 0px rgba(0,0,0,0.1), 0 8px 16px 0px rgba(0,0,0,0.1);
}
#l_cover {
  min-height: 64px;
}
.cover-wrapper {
  top: 0;
  left: 0;
  max-width: 100%;
  height: 100vh;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  flex-wrap: nowrap;
  -webkit-flex-wrap: nowrap;
  -khtml-flex-wrap: nowrap;
  -moz-flex-wrap: nowrap;
  -o-flex-wrap: nowrap;
  -ms-flex-wrap: nowrap;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: vertical;
  -moz-box-orient: vertical;
  -webkit-flex-direction: column;
  -ms-flex-direction: column;
  flex-direction: column;
  align-items: center;
  align-self: center;
  align-content: center;
  color: var(--color-site-inner);
  padding: 0 16px;
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  position: relative;
  overflow: hidden;
  margin-bottom: -100px;
}
.cover-wrapper .cover-bg {
  position: absolute;
  width: 100%;
  height: 100%;
  background-position: center;
  background-size: cover;
  -webkit-background-size: cover;
  -moz-background-size: cover;
}
.cover-wrapper .cover-bg.lazyload:not(.loaded) {
  opacity: 0;
  -webkit-opacity: 0;
  -moz-opacity: 0;
}
.cover-wrapper .cover-bg.lazyload.loaded {
  animation-delay: 0s;
  animation-duration: 0.5s;
  animation-fill-mode: forwards;
  animation-timing-function: ease-out;
  animation-name: fadeIn;
}
@-moz-keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
    transform: scale(1.02);
    -webkit-transform: scale(1.02);
    -khtml-transform: scale(1.02);
    -moz-transform: scale(1.02);
    -o-transform: scale(1.02);
    -ms-transform: scale(1.02);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
    transform: scale(1.02);
    -webkit-transform: scale(1.02);
    -khtml-transform: scale(1.02);
    -moz-transform: scale(1.02);
    -o-transform: scale(1.02);
    -ms-transform: scale(1.02);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-o-keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
    transform: scale(1.02);
    -webkit-transform: scale(1.02);
    -khtml-transform: scale(1.02);
    -moz-transform: scale(1.02);
    -o-transform: scale(1.02);
    -ms-transform: scale(1.02);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
    transform: scale(1.02);
    -webkit-transform: scale(1.02);
    -khtml-transform: scale(1.02);
    -moz-transform: scale(1.02);
    -o-transform: scale(1.02);
    -ms-transform: scale(1.02);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
.cover-wrapper .cover-body {
  z-index: 1;
  position: relative;
  width: 100%;
  height: 100%;
}
.cover-wrapper#full {
  height: calc(100vh + 100px);
  padding-bottom: 100px;
}
.cover-wrapper#half {
  max-height: 640px;
  min-height: 400px;
  height: calc(36vh - 64px + 200px);
}
.cover-wrapper #scroll-down {
  width: 100%;
  height: 64px;
  position: absolute;
  bottom: 100px;
  text-align: center;
  cursor: pointer;
}
.cover-wrapper #scroll-down .scroll-down-effects {
  color: #fff;
  font-size: 24px;
  line-height: 64px;
  position: absolute;
  width: 24px;
  left: calc(50% - 12px);
  text-shadow: 0 1px 2px rgba(0,0,0,0.1);
  animation: scroll-down-effect 1.5s infinite;
  -webkit-animation: scroll-down-effect 1.5s infinite;
  -khtml-animation: scroll-down-effect 1.5s infinite;
  -moz-animation: scroll-down-effect 1.5s infinite;
  -o-animation: scroll-down-effect 1.5s infinite;
  -ms-animation: scroll-down-effect 1.5s infinite;
}
@-moz-keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-webkit-keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-o-keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
.cover-wrapper .cover-body {
  margin-top: 64px;
  margin-bottom: 100px;
}
.cover-wrapper .cover-body,
.cover-wrapper .cover-body .top,
.cover-wrapper .cover-body .bottom {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: vertical;
  -moz-box-orient: vertical;
  -webkit-flex-direction: column;
  -ms-flex-direction: column;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  -webkit-justify-content: center;
  -khtml-justify-content: center;
  -moz-justify-content: center;
  -o-justify-content: center;
  -ms-justify-content: center;
  max-width: 100%;
}
.cover-wrapper .cover-body .bottom {
  margin-top: 32px;
}
.cover-wrapper .cover-body .title {
  font-family: "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Helvetica, monospace;
  font-size: 3.125rem;
  line-height: 1.2;
  text-shadow: 0 1px 2px rgba(0,0,0,0.1);
}
.cover-wrapper .cover-body .subtitle {
  font-size: 20px;
}
.cover-wrapper .cover-body .logo {
  max-height: 120px;
  max-width: calc(100% - 4 * 16px);
}
@media screen and (min-height: 1024px) {
  .cover-wrapper .cover-body .title {
    font-size: 3rem;
  }
  .cover-wrapper .cover-body .subtitle {
    font-size: 1.05rem;
  }
  .cover-wrapper .cover-body .logo {
    max-height: 150px;
  }
}
.cover-wrapper .cover-body .m_search {
  position: relative;
  max-width: calc(100% - 16px);
  width: 320px;
  vertical-align: middle;
}
.cover-wrapper .cover-body .m_search .form {
  position: relative;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  width: 100%;
}
.cover-wrapper .cover-body .m_search .icon,
.cover-wrapper .cover-body .m_search .input {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.cover-wrapper .cover-body .m_search .icon {
  position: absolute;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  line-height: 2.5rem;
  width: 32px;
  top: 0;
  left: 5px;
  color: rgba(68,68,68,0.75);
}
.cover-wrapper .cover-body .m_search .input {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  height: 2.5rem;
  width: 100%;
  box-shadow: none;
  -webkit-box-shadow: none;
  box-sizing: border-box;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  font-size: 0.875rem;
  -webkit-appearance: none;
  padding-left: 36px;
  border-radius: 1.4rem;
  -webkit-border-radius: 1.4rem;
  background: rgba(255,255,255,0.6);
  backdrop-filter: blur(10px);
  border: none;
  color: var(--color-text);
}
@media screen and (max-width: 500px) {
  .cover-wrapper .cover-body .m_search .input {
    padding-left: 36px;
  }
}
.cover-wrapper .cover-body .m_search .input:hover {
  background: rgba(255,255,255,0.8);
}
.cover-wrapper .cover-body .m_search .input:focus {
  background: #fff;
}
.cover-wrapper .list-h {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: horizontal;
  -moz-box-orient: horizontal;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row;
  flex-wrap: wrap;
  -webkit-flex-wrap: wrap;
  -khtml-flex-wrap: wrap;
  -moz-flex-wrap: wrap;
  -o-flex-wrap: wrap;
  -ms-flex-wrap: wrap;
  align-items: stretch;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
.cover-wrapper .list-h a {
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  -webkit-flex: 1 0;
  -ms-flex: 1 0;
  flex: 1 0;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  font-weight: 600;
}
.cover-wrapper .list-h a img {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  border-radius: 2px;
  -webkit-border-radius: 2px;
  margin: 4px;
  min-width: 40px;
  max-width: 44px;
}
@media screen and (max-width: 768px) {
  .cover-wrapper .list-h a img {
    min-width: 36px;
    max-width: 40px;
  }
}
@media screen and (max-width: 500px) {
  .cover-wrapper .list-h a img {
    margin: 2px 4px;
    min-width: 32px;
    max-width: 36px;
  }
}
@media screen and (max-width: 375px) {
  .cover-wrapper .list-h a img {
    min-width: 28px;
    max-width: 32px;
  }
}
.cover-wrapper {
  max-width: 100%;
}
.cover-wrapper.search .bottom .menu {
  margin-top: 16px;
}
.cover-wrapper.search .bottom .menu .list-h a {
  white-space: nowrap;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: horizontal;
  -moz-box-orient: horizontal;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row;
  align-items: baseline;
  padding: 2px;
  margin: 4px;
  color: var(--color-site-inner);
  opacity: 0.75;
  -webkit-opacity: 0.75;
  -moz-opacity: 0.75;
  text-shadow: 0 1px 2px rgba(0,0,0,0.05);
  border-bottom: 2px solid transparent;
}
.cover-wrapper.search .bottom .menu .list-h a i {
  margin-right: 4px;
}
.cover-wrapper.search .bottom .menu .list-h a p {
  font-size: 0.9375rem;
}
.cover-wrapper.search .bottom .menu .list-h a:hover,
.cover-wrapper.search .bottom .menu .list-h a.active,
.cover-wrapper.search .bottom .menu .list-h a:active {
  opacity: 1;
  -webkit-opacity: 1;
  -moz-opacity: 1;
  border-bottom: 2px solid var(--color-site-inner);
}
@font-face {
  font-family: 'UbuntuMono';
  src: url("https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/UbuntuMono/UbuntuMono-Regular.ttf");
  font-weight: 'normal';
  font-style: 'normal';
  font-display: swap;
}
@font-face {
  font-family: 'Varela Round';
  src: url("https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/VarelaRound/VarelaRound-Regular.ttf");
  font-weight: 'normal';
  font-style: 'normal';
  font-display: swap;
}
.l_header {
  position: fixed;
  z-index: 1000;
  top: 0;
  width: 100%;
  height: 64px;
  background: var(--color-card);
  box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
  -webkit-box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
}
.l_header.auto {
  transition: opacity 0.4s ease;
  -webkit-transition: opacity 0.4s ease;
  -khtml-transition: opacity 0.4s ease;
  -moz-transition: opacity 0.4s ease;
  -o-transition: opacity 0.4s ease;
  -ms-transition: opacity 0.4s ease;
  visibility: hidden;
}
.l_header.auto.show {
  opacity: 1 !important;
  -webkit-opacity: 1 !important;
  -moz-opacity: 1 !important;
  visibility: visible;
}
.l_header .container {
  margin-left: 16px;
  margin-right: 16px;
}
.l_header #wrapper {
  height: 100%;
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
.l_header #wrapper .nav-main,
.l_header #wrapper .nav-sub {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  flex-wrap: nowrap;
  -webkit-flex-wrap: nowrap;
  -khtml-flex-wrap: nowrap;
  -moz-flex-wrap: nowrap;
  -o-flex-wrap: nowrap;
  -ms-flex-wrap: nowrap;
  justify-content: space-between;
  -webkit-justify-content: space-between;
  -khtml-justify-content: space-between;
  -moz-justify-content: space-between;
  -o-justify-content: space-between;
  -ms-justify-content: space-between;
  align-items: center;
}
.l_header #wrapper .nav-main {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.l_header #wrapper.sub .nav-main {
  transform: translateY(-64px);
  -webkit-transform: translateY(-64px);
  -khtml-transform: translateY(-64px);
  -moz-transform: translateY(-64px);
  -o-transform: translateY(-64px);
  -ms-transform: translateY(-64px);
}
.l_header #wrapper .nav-sub {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  opacity: 0;
  -webkit-opacity: 0;
  -moz-opacity: 0;
  height: 64px;
  width: calc(100% - 2 * 16px);
  position: absolute;
}
.l_header #wrapper .nav-sub ::-webkit-scrollbar {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
}
@media screen and (min-width: 2048px) {
  .l_header #wrapper .nav-sub {
    max-width: 55vw;
    margin: auto;
  }
}
.l_header #wrapper.sub .nav-sub {
  opacity: 1;
  -webkit-opacity: 1;
  -moz-opacity: 1;
}
.l_header #wrapper .title {
  position: relative;
  color: var(--color-text);
  padding-left: 24px;
  max-height: 64px;
}
.l_header #wrapper .nav-main .title {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  flex-shrink: 0;
  line-height: 64px;
  padding: 0 24px;
  font-size: 1.25rem;
  font-family: "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Helvetica, monospace;
}
.l_header #wrapper .nav-main .title img {
  height: 64px;
}
.l_header .nav-sub {
  max-width: 1080px;
  margin: auto;
}
.l_header .nav-sub .title {
  font-weight: bold;
  font-family: UbuntuMono, "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Menlo, Monaco, monospace, sans-serif;
  line-height: 1.2;
  max-height: 64px;
  white-space: normal;
  flex-shrink: 1;
}
.l_header .switcher {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  line-height: 64px;
  align-items: center;
}
.l_header .switcher .s-toc {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
}
@media screen and (max-width: 768px) {
  .l_header .switcher .s-toc {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: -ms-flexbox /* TWEENER - IE 10 */;
    display: -webkit-flex /* NEW - Chrome */;
    display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
    display: flex;
  }
}
.l_header .switcher >li {
  height: 48px;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  margin: 2px;
}
@media screen and (max-width: 500px) {
  .l_header .switcher >li {
    margin: 0 1px;
    height: 48px;
  }
}
.l_header .switcher >li >a {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  justify-content: center;
  -webkit-justify-content: center;
  -khtml-justify-content: center;
  -moz-justify-content: center;
  -o-justify-content: center;
  -ms-justify-content: center;
  align-items: center;
  width: 48px;
  height: 48px;
  padding: 0.85em 1.1em;
  border-radius: 100px;
  -webkit-border-radius: 100px;
  border: none;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  color: #3dd9b6;
}
.l_header .switcher >li >a:hover {
  border: none;
}
.l_header .switcher >li >a.active,
.l_header .switcher >li >a:active {
  border: none;
  background: var(--color-site-bg);
}
@media screen and (max-width: 500px) {
  .l_header .switcher >li >a {
    width: 36px;
    height: 48px;
  }
}
.l_header .nav-sub .switcher {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
}
.l_header .m_search {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  height: 64px;
  width: 240px;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
@media screen and (max-width: 1024px) {
  .l_header .m_search {
    width: 44px;
    min-width: 44px;
  }
  .l_header .m_search input::placeholder {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
  }
  .l_header .m_search:hover {
    width: 240px;
  }
  .l_header .m_search:hover input::placeholder {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@media screen and (min-width: 500px) {
  .l_header .m_search:hover .input {
    width: 100%;
  }
  .l_header .m_search:hover .input::placeholder {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@media screen and (max-width: 500px) {
  .l_header .m_search {
    min-width: 0;
  }
  .l_header .m_search input::placeholder {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
.l_header .m_search .form {
  position: relative;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  width: 100%;
  align-items: center;
}
.l_header .m_search .icon {
  position: absolute;
  width: 36px;
  left: 5px;
  color: var(--color-meta);
}
@media screen and (max-width: 500px) {
  .l_header .m_search .icon {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: none;
  }
}
.l_header .m_search .input {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  padding-top: 8px;
  padding-bottom: 8px;
  line-height: 1.3;
  width: 100%;
  color: var(--color-text);
  background: #fafafa;
  box-shadow: none;
  -webkit-box-shadow: none;
  box-sizing: border-box;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  padding-left: 40px;
  font-size: 0.875rem;
  border-radius: 8px;
  -webkit-border-radius: 8px;
  border: none;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
@media screen and (min-width: 500px) {
  .l_header .m_search .input:focus {
    box-shadow: 0 4px 8px 0px rgba(0,0,0,0.1);
    -webkit-box-shadow: 0 4px 8px 0px rgba(0,0,0,0.1);
  }
}
@media screen and (max-width: 500px) {
  .l_header .m_search .input {
    background: var(--color-block);
    padding-left: 8px;
    border: none;
  }
  .l_header .m_search .input:hover,
  .l_header .m_search .input:focus {
    border: none;
  }
}
@media (max-width: 500px) {
  .l_header .m_search {
    left: 0;
    width: 0;
    overflow: hidden;
    position: absolute;
    background: #fff;
    transition: all 0.28s ease;
    -webkit-transition: all 0.28s ease;
    -khtml-transition: all 0.28s ease;
    -moz-transition: all 0.28s ease;
    -o-transition: all 0.28s ease;
    -ms-transition: all 0.28s ease;
  }
  .l_header .m_search .input {
    border-radius: 32px;
    -webkit-border-radius: 32px;
    margin-left: 16px;
    padding-left: 16px;
  }
  .l_header.z_search-open .m_search {
    width: 100%;
  }
  .l_header.z_search-open .m_search .input {
    width: calc(100% - 120px);
  }
}
ul.m-pc >li>a {
  color: inherit;
  border-bottom: 2px solid transparent;
}
ul.m-pc >li>a:active,
ul.m-pc >li>a.active {
  border-bottom: 2px solid #3dd9b6;
}
ul.m-pc li:hover >ul.list-v,
ul.list-v li:hover >ul.list-v {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
}
ul.nav-list-h {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  align-items: stretch;
}
ul.nav-list-h>li {
  position: relative;
  justify-content: center;
  -webkit-justify-content: center;
  -khtml-justify-content: center;
  -moz-justify-content: center;
  -o-justify-content: center;
  -ms-justify-content: center;
  height: 100%;
  line-height: 2.4;
  border-radius: 4px;
  -webkit-border-radius: 4px;
}
ul.nav-list-h>li >a {
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  font-weight: 600;
}
ul.list-v {
  z-index: 1;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  position: absolute;
  background: var(--color-card);
  box-shadow: 0 2px 4px 0px rgba(0,0,0,0.08), 0 4px 8px 0px rgba(0,0,0,0.08), 0 8px 16px 0px rgba(0,0,0,0.08);
  -webkit-box-shadow: 0 2px 4px 0px rgba(0,0,0,0.08), 0 4px 8px 0px rgba(0,0,0,0.08), 0 8px 16px 0px rgba(0,0,0,0.08);
  margin-top: -6px;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  padding: 8px 0;
}
ul.list-v.show {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
}
ul.list-v hr {
  margin-top: 8px;
  margin-bottom: 8px;
}
ul.list-v >li {
  white-space: nowrap;
  word-break: keep-all;
}
ul.list-v >li.header {
  font-size: 0.78125rem;
  font-weight: bold;
  line-height: 2em;
  color: var(--color-meta);
  margin: 8px 16px 4px;
}
ul.list-v >li.header i {
  margin-right: 8px;
}
ul.list-v >li ul {
  margin-left: 0;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  margin-top: -40px;
}
ul.list-v .aplayer-container {
  min-height: 64px;
  padding: 6px 16px;
}
ul.list-v >li>a {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  color: var(--color-list);
  font-size: 0.875rem;
  font-weight: bold;
  line-height: 36px;
  padding: 0 20px 0 16px;
  text-overflow: ellipsis;
  margin: 0 4px;
  border-radius: 4px;
  -webkit-border-radius: 4px;
}
@media screen and (max-width: 1024px) {
  ul.list-v >li>a {
    line-height: 40px;
  }
}
ul.list-v >li>a >i {
  margin-right: 8px;
}
ul.list-v >li>a:active,
ul.list-v >li>a.active {
  color: var(--color-list-hl);
}
ul.list-v >li>a:hover {
  color: var(--color-list-hl);
  background: var(--color-site-bg);
}
.l_header .menu >ul>li>a {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  padding: 0 8px;
}
.l_header .menu >ul>li>a >i {
  margin-right: 4px;
}
.l_header ul.nav-list-h>li {
  color: var(--color-list);
  line-height: 64px;
}
.l_header ul.nav-list-h>li >a {
  max-height: 64px;
  overflow: hidden;
  color: inherit;
}
.l_header ul.nav-list-h>li >a:active,
.l_header ul.nav-list-h>li >a.active {
  color: #3dd9b6;
}
.l_header ul.nav-list-h>li:hover>a {
  color: var(--color-list-hl);
}
.l_header ul.nav-list-h>li i.music {
  animation: rotate-effect 1.5s linear infinite;
  -webkit-animation: rotate-effect 1.5s linear infinite;
  -khtml-animation: rotate-effect 1.5s linear infinite;
  -moz-animation: rotate-effect 1.5s linear infinite;
  -o-animation: rotate-effect 1.5s linear infinite;
  -ms-animation: rotate-effect 1.5s linear infinite;
}
@-moz-keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
@-webkit-keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
@-o-keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
@keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
.menu-phone li ul.list-v {
  right: calc(100% - 0.5 * 16px);
}
.menu-phone li ul.list-v ul {
  right: calc(100% - 0.5 * 16px);
}
#wrapper {
  max-width: 1080px;
  margin: auto;
}
@media screen and (min-width: 2048px) {
  #wrapper {
    max-width: 55vw;
  }
}
#wrapper .menu {
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  -webkit-flex: 1 1;
  -ms-flex: 1 1;
  flex: 1 1;
  margin: 0 16px 0 0;
}
#wrapper .menu .list-v ul {
  left: calc(100% - 0.5 * 16px);
}
.menu-phone {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  margin-top: 16px;
  right: 8px;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.menu-phone ul {
  right: calc(100% - 0.5 * 16px);
}
@media screen and (max-width: 500px) {
  .menu-phone {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: block;
  }
}
.l_header {
  max-width: 65vw;
  left: calc((100% - 65vw) * 0.5);
  border-bottom-left-radius: 8px;
  border-bottom-right-radius: 8px;
}
@media screen and (max-width: 2048px) {
  .l_header {
    max-width: 1112px;
    left: calc((100% - 1112px) * 0.5);
  }
}
@media screen and (max-width: 1112px) {
  .l_header {
    left: 0;
    border-radius: 0;
    -webkit-border-radius: 0;
    max-width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .l_header .container {
    margin-left: 0;
    margin-right: 0;
  }
  .l_header #wrapper .nav-main .title {
    padding-left: 16px;
    padding-right: 16px;
  }
  .l_header #wrapper .nav-sub {
    width: 100%;
  }
  .l_header #wrapper .nav-sub .title {
    overflow-y: scroll;
    margin-top: 2px;
    padding: 8px 16px;
  }
  .l_header #wrapper .switcher {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: -ms-flexbox /* TWEENER - IE 10 */;
    display: -webkit-flex /* NEW - Chrome */;
    display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
    display: flex;
    margin-right: 8px;
  }
  .l_header .menu {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: none;
  }
}
@media screen and (max-width: 500px) {
  .list-v li {
    max-width: 270px;
  }
}
#u-search {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  padding: 60px 20px;
  z-index: 1001;
}
@media screen and (max-width: 680px) {
  #u-search {
    padding: 0px;
  }
}

  </style>
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  
<script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
    '.kill-t{'+
      'font-size: 2rem;'+
    '}'+
    '.kill-c{'+
      'font-size: 1.2rem;'+
    '}'+
		'#l_header,#l_body{'+
			'display: none;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        `<span class="kill-t"><b>抱歉，您的浏览器无法访问本站</b></span><br/>`+
        `<span class="kill-c">微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</span><br/>`+
        `<a target="_blank" rel="noopener" href="https://blogs.windows.com/windowsexperience/2021/05/19/the-future-of-internet-explorer-on-windows-10-is-in-microsoft-edge/"><strong>了解详情 ></strong></a>`+
    '</div>');
</script>


<noscript>
	<style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
    .kill-t{
      font-size: 2rem;
    }
    .kill-c{
      font-size: 1.2rem;
    }
		#l_header,#l_body{
			display: none;
		}
	</style>
    <div class="kill-noscript">
        <span class="kill-t"><b>抱歉，您的浏览器无法访问本站</b></span><br/>
        <span class="kill-c">本页面需要浏览器支持（启用）JavaScript</span><br/>
        <a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=启用JavaScript"><strong>了解详情 ></strong></a>
    </div>
</noscript>


  <script>
  /************这个文件存放不需要重载的全局变量和全局函数*********/
  window.volantis = {}; // volantis 全局变量
  volantis.debug = "env"; // 调试模式
  volantis.dom = {}; // 页面Dom see: /source/js/app.js etc.

  volantis.GLOBAL_CONFIG ={
    debug: "env",
    cdn: {"js":{"app":"/js/app.js","parallax":"/js/plugins/parallax.js","rightMenu":"/js/plugins/rightMenu.js","rightMenus":"/js/plugins/rightMenus.js","sites":"/js/plugins/tags/sites.js","friends":"/js/plugins/tags/friends.js","contributors":"/js/plugins/tags/contributors.js","search":"/js/search/hexo.js"},"css":{"style":"/css/style.css"}},
    default: {"avatar":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/avatar/round/3442075.svg","link":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/link/8f277b4ee0ecd.svg","cover":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/cover/76b86c0226ffd.svg","image":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/image/2659360.svg"},
    lastupdate: new Date(1693066257736),
    sidebar: {
      for_page: ["blogger","category","tagcloud","donate","text"],
      for_post: ["toc"],
      webinfo: {
        lastupd: {
          enable: true,
          friendlyShow: true
        },
        runtime: {
          data: "2020/01/01",
          unit: "天"
        }
      }
    },
    plugins: {
      message: {"enable":true,"css":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/izitoast/dist/css/iziToast.min.css","js":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/izitoast/dist/js/iziToast.min.js","icon":{"default":"fa-solid fa-info-circle light-blue","quection":"fa-solid fa-question-circle light-blue"},"time":{"default":5000,"quection":20000},"position":"topRight","transitionIn":"bounceInLeft","transitionOut":"fadeOutRight","titleColor":"var(--color-text)","messageColor":"var(--color-text)","backgroundColor":"var(--color-card)","zindex":2147483647,"copyright":{"enable":true,"title":"知识共享许可协议","message":"请遵守 CC BY-NC-SA 4.0 协议。","icon":"far fa-copyright light-blue"},"aplayer":{"enable":true,"play":"fa-solid fa-play","pause":"fa-solid fa-pause"},"rightmenu":{"enable":true,"notice":true}},
      fancybox: {"css":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fancyapps/ui/dist/fancybox.css","js":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fancyapps/ui/dist/fancybox.umd.js"},
      
      
      
    }
  }

  /******************** volantis.EventListener ********************************/
  // 事件监听器 see: /source/js/app.js
  volantis.EventListener = {}
  // 这里存放pjax切换页面时将被移除的事件监听器
  volantis.EventListener.list = []
  //构造方法
  function volantisEventListener(type, f, ele) {
    this.type = type
    this.f = f
    this.ele = ele
  }
  // 移除事件监听器
  volantis.EventListener.remove = () => {
    volantis.EventListener.list.forEach(function (i) {
      i.ele.removeEventListener(i.type, i.f, false)
    })
    volantis.EventListener.list = []
  }
  /******************** volantis.dom.$ ********************************/
  // 注：这里没有选择器，也没有forEach一次只处理一个dom，这里重新封装主题常用的dom方法，返回的是dom对象，对象包含了以下方法，同时保留dom的原生API
  function volantisDom(ele) {
    if (!ele) ele = document.createElement("div")
    this.ele = ele;
    // ==============================================================
    this.ele.find = (c) => {
      let q = this.ele.querySelector(c)
      if (q)
        return new volantisDom(q)
    }
    // ==============================================================
    this.ele.hasClass = (c) => {
      return this.ele.className.match(new RegExp('(\\s|^)' + c + '(\\s|$)'));
    }
    this.ele.addClass = (c) => {
      this.ele.classList.add(c);
      return this.ele
    }
    this.ele.removeClass = (c) => {
      this.ele.classList.remove(c);
      return this.ele
    }
    this.ele.toggleClass = (c) => {
      if (this.ele.hasClass(c)) {
        this.ele.removeClass(c)
      } else {
        this.ele.addClass(c)
      }
      return this.ele
    }
    // ==============================================================
    // 参数 r 为 true 表示pjax切换页面时事件监听器将被移除，false不移除
    this.ele.on = (c, f, r = 1) => {
      this.ele.addEventListener(c, f, false)
      if (r) {
        volantis.EventListener.list.push(new volantisEventListener(c, f, this.ele))
      }
      return this.ele
    }
    this.ele.click = (f, r) => {
      this.ele.on("click", f, r)
      return this.ele
    }
    this.ele.scroll = (f, r) => {
      this.ele.on("scroll", f, r)
      return this.ele
    }
    // ==============================================================
    this.ele.html = (c) => {
      // if(c=== undefined){
      //   return this.ele.innerHTML
      // }else{
      this.ele.innerHTML = c
      return this.ele
      // }
    }
    // ==============================================================
    this.ele.hide = (c) => {
      this.ele.style.display = "none"
      return this.ele
    }
    this.ele.show = (c) => {
      this.ele.style.display = "block"
      return this.ele
    }
    // ==============================================================
    return this.ele
  }
  volantis.dom.$ = (ele) => {
    return !!ele ? new volantisDom(ele) : null;
  }
  /******************** RunItem ********************************/
  function RunItem() {
    this.list = []; // 存放回调函数
    this.start = () => {
      for (var i = 0; i < this.list.length; i++) {
        this.list[i].run();
      }
    };
    this.push = (fn, name, setRequestAnimationFrame = true) => {
      let myfn = fn
      if (setRequestAnimationFrame) {
        myfn = ()=>{
          volantis.requestAnimationFrame(fn)
        }
      }
      var f = new Item(myfn, name);
      this.list.push(f);
    };
    this.remove = (name) =>{
      for (let index = 0; index < this.list.length; index++) {
        const e = this.list[index];
        if (e.name == name) {
          this.list.splice(index,1);
        }
      }
    }
    // 构造一个可以run的对象
    function Item(fn, name) {
      // 函数名称
      this.name = name || fn.name;
      // run方法
      this.run = () => {
        try {
          fn()
        } catch (error) {
          console.log(error);
        }
      };
    }
  }
  /******************** Pjax ********************************/
  // /layout/_plugins/pjax/index.ejs
  // volantis.pjax.send(callBack[,"callBackName"]) 传入pjax:send回调函数
  // volantis.pjax.push(callBack[,"callBackName"]) 传入pjax:complete回调函数
  // volantis.pjax.error(callBack[,"callBackName"]) 传入pjax:error回调函数
  volantis.pjax = {};
  volantis.pjax.method = {
    complete: new RunItem(),
    error: new RunItem(),
    send: new RunItem(),
  };
  volantis.pjax = Object.assign(volantis.pjax, {
    push: volantis.pjax.method.complete.push,
    error: volantis.pjax.method.error.push,
    send: volantis.pjax.method.send.push,
  });
  /******************** RightMenu ********************************/
  // volantis.rightmenu.handle(callBack[,"callBackName"]) 外部菜单项控制
  // 可在 volantis.mouseEvent 处获取右键事件
  volantis.rightmenu = {};
  volantis.rightmenu.method = {
    handle: new RunItem(),
  }
  volantis.rightmenu = Object.assign(volantis.rightmenu, {
    handle: volantis.rightmenu.method.handle.push,
  });
  /********************  Dark Mode  ********************************/
  // /layout/_partial/scripts/darkmode.ejs
  // volantis.dark.mode 当前模式 dark or light
  // volantis.dark.toggle() 暗黑模式触发器
  // volantis.dark.push(callBack[,"callBackName"]) 传入触发器回调函数
  volantis.dark = {};
  volantis.dark.method = {
    toggle: new RunItem(),
  };
  volantis.dark = Object.assign(volantis.dark, {
    push: volantis.dark.method.toggle.push,
  });
  /********************  Message  ********************************/
  // VolantisApp.message
  /********************  isMobile  ********************************/
  // /source/js/app.js
  // volantis.isMobile
  // volantis.isMobileOld
  /********************脚本动态加载函数********************************/
  // volantis.js(src, cb)  cb 可以传入onload回调函数 或者 JSON对象 例如: volantis.js("src", ()=>{}) 或 volantis.js("src", {defer:true,onload:()=>{}})
  // volantis.css(src)

  // 返回Promise对象，如下方法同步加载资源，这利于处理文件资源之间的依赖关系，例如：APlayer 需要在 MetingJS 之前加载
  // (async () => {
  //     await volantis.js("...theme.plugins.aplayer.js.aplayer...")
  //     await volantis.js("...theme.plugins.aplayer.js.meting...")
  // })();

  // 已经加入了setTimeout
  volantis.js = (src, cb) => {
    return new Promise(resolve => {
      setTimeout(function () {
        var HEAD = document.getElementsByTagName("head")[0] || document.documentElement;
        var script = document.createElement("script");
        script.setAttribute("type", "text/javascript");
        if (cb) {
          if (JSON.stringify(cb)) {
            for (let p in cb) {
              if (p == "onload") {
                script[p] = () => {
                  cb[p]()
                  resolve()
                }
              } else {
                script[p] = cb[p]
                script.onload = resolve
              }
            }
          } else {
            script.onload = () => {
              cb()
              resolve()
            };
          }
        } else {
          script.onload = resolve
        }
        script.setAttribute("src", src);
        HEAD.appendChild(script);
      });
    });
  }
  volantis.css = (src) => {
    return new Promise(resolve => {
      setTimeout(function () {
        var link = document.createElement('link');
        link.rel = "stylesheet";
        link.href = src;
        link.onload = resolve;
        document.getElementsByTagName("head")[0].appendChild(link);
      });
    });
  }
  /********************按需加载的插件********************************/
  // volantis.import.jQuery().then(()=>{})
  volantis.import = {
    jQuery: () => {
      if (typeof jQuery == "undefined") {
        return volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/jquery/dist/jquery.min.js")
      } else {
        return new Promise(resolve => {
          resolve()
        });
      }
    }
  }
  /********************** requestAnimationFrame ********************************/
  // 1、requestAnimationFrame 会把每一帧中的所有 DOM 操作集中起来，在一次重绘或回流中就完成，并且重绘或回流的时间间隔紧紧跟随浏览器的刷新频率，一般来说，这个频率为每秒60帧。
  // 2、在隐藏或不可见的元素中，requestAnimationFrame 将不会进行重绘或回流，这当然就意味着更少的的 cpu，gpu 和内存使用量。
  volantis.requestAnimationFrame = (fn)=>{
    if (!window.requestAnimationFrame) {
      window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame;
    }
    window.requestAnimationFrame(fn)
  }
  /************************ layoutHelper *****************************************/
  volantis.layoutHelper = (helper, html, opt)=>{
    opt = Object.assign({clean:false, pjax:true}, opt)
    function myhelper(helper, html, clean) {
      volantis.tempDiv = document.createElement("div");
      volantis.tempDiv.innerHTML = html;
      let layoutHelper = document.querySelector("#layoutHelper-"+helper)
      if (layoutHelper) {
        if (clean) {
          layoutHelper.innerHTML = ""
        }
        layoutHelper.append(volantis.tempDiv);
      }
    }
    myhelper(helper, html, opt.clean)
    if (opt.pjax) {
      volantis.pjax.push(()=>{
        myhelper(helper, html, opt.clean)
      },"layoutHelper-"+helper)
    }
  }
  /****************************** 滚动事件处理 ****************************************/
  volantis.scroll = {
    engine: new RunItem(),
    unengine: new RunItem(),
  };
  volantis.scroll = Object.assign(volantis.scroll, {
    push: volantis.scroll.engine.push,
  });
  // 滚动条距离顶部的距离
  volantis.scroll.getScrollTop = () =>{
    let scrollPos;
    if (window.pageYOffset) {
      scrollPos = window.pageYOffset;
    } else if (document.compatMode && document.compatMode != 'BackCompat') {
      scrollPos = document.documentElement.scrollTop;
    } else if (document.body) {
      scrollPos = document.body.scrollTop;
    }
    return scrollPos;
  }
  // 使用 requestAnimationFrame 处理滚动事件
  // `volantis.scroll.del` 中存储了一个数值, 该数值检测一定时间间隔内滚动条滚动的位移, 数值的检测频率是浏览器的刷新频率. 数值为正数时, 表示向下滚动. 数值为负数时, 表示向上滚动.
  volantis.scroll.handleScrollEvents = () => {
    volantis.scroll.lastScrollTop = volantis.scroll.getScrollTop()
    function loop() {
      const scrollTop = volantis.scroll.getScrollTop();
      if (volantis.scroll.lastScrollTop !== scrollTop) {
        volantis.scroll.del = scrollTop - volantis.scroll.lastScrollTop;
        volantis.scroll.lastScrollTop = scrollTop;
        // if (volantis.scroll.del > 0) {
        //   console.log("向下滚动");
        // } else {
        //   console.log("向上滚动");
        // }
        // 注销过期的unengine未滚动事件
        volantis.scroll.unengine.list=[]
        volantis.scroll.engine.start();
      }else{
        volantis.scroll.unengine.start();
      }
      volantis.requestAnimationFrame(loop)
    }
    volantis.requestAnimationFrame(loop)
  }
  volantis.scroll.handleScrollEvents()
  volantis.scroll.ele = null;
  // 触发页面滚动至目标元素位置
  volantis.scroll.to = (ele, option = {}) => {
    if (!ele) return;
    volantis.scroll.ele = ele;
    // 默认配置
    opt = {
      top: ele.getBoundingClientRect().top + document.documentElement.scrollTop,
      behavior: "smooth"
    }
    // 定义配置
    if ("top" in option) {
      opt.top = option.top
    }
    if ("behavior" in option) {
      opt.behavior = option.behavior
    }
    if ("addTop" in option) {
      opt.top += option.addTop
    }
    if (!("observerDic" in option)) {
      option.observerDic = 100
    }
    // 滚动
    window.scrollTo(opt);
    // 监视器
    // 监视并矫正元素滚动到指定位置
    // 用于处理 lazyload 引起的 cls 导致的定位失败问题
    // option.observer = false
    if (option.observer) {
      setTimeout(() => {
        if (volantis.scroll.ele != ele) {
          return
        }
        volantis.scroll.unengine.push(() => {
          let me = ele.getBoundingClientRect().top
          if(!(me >= -option.observerDic && me <= option.observerDic)){
            volantis.scroll.to(ele, option)
          }
          volantis.scroll.unengine.remove("unengineObserver")
        },"unengineObserver")
      },1000)
    }
  }
  /********************** Content Visibility ********************************/
  // 见 source/css/first.styl 如果遇到任何问题 删除 .post-story 即可
  // 一个元素被声明 content-visibility 属性后 如果元素不在 viewport 中 浏览器不会计算其后代元素样式和属性 从而节省 Style & Layout 耗时
  // content-visibility 的副作用: 锚点失效 等等(实验初期 暂不明确), 使用此方法清除样式
  volantis.cleanContentVisibility = ()=>{
    if (document.querySelector(".post-story")) {
      console.log("cleanContentVisibility");
      document.querySelectorAll(".post-story").forEach(e=>{
        e.classList.remove("post-story")
      })
    }
  }
  /******************************************************************************/
  /******************************************************************************/
  /******************************************************************************/
  //图像加载出错时的处理
  function errorImgAvatar(img) {
    img.src = "https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/avatar/round/3442075.svg";
    img.onerror = null;
  }
  function errorImgCover(img) {
    img.src = "https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/cover/76b86c0226ffd.svg";
    img.onerror = null;
  }
  /******************************************************************************/
</script>

  <!-- import head_end begin -->
  <!-- import head_end end -->
  <!-- Custom Files headEnd begin-->
  
  <!-- Custom Files headEnd end-->
</head>
  <body itemscope itemtype="http://schema.org/WebPage">
    <!-- import body_begin begin-->
    <!-- import body_begin end-->
    <!-- Custom Files bodyBegin begin-->
    
    <!-- Custom Files bodyBegin end-->
    <header itemscope itemtype="http://schema.org/WPHeader" id="l_header" class="l_header auto shadow floatable blur show" style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fa-solid fa-comments fa-fw" target="_self"  href="/" onclick="return false;" title="comment"></a></li>
        
          <li><a id="s-toc" class="s-toc fa-solid fa-list fa-fw" target="_self"  href="/" onclick="return false;" title="toc"></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img no-lazy class='logo' src='https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/Logo-NavBar@3x.png'/>
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/" title="博客"
                  
                  
                  
                    active-action="action-home"
                  >
                  <i class='fa-solid fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/categories/" title="分类"
                  
                  
                  
                    active-action="action-categories"
                  >
                  <i class='fa-solid fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/tags/" title="标签"
                  
                  
                  
                    active-action="action-tags"
                  >
                  <i class='fa-solid fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/archives/" title="归档"
                  
                  
                  
                    active-action="action-archives"
                  >
                  <i class='fa-solid fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/friends/" title="友链"
                  
                  
                  
                    active-action="action-friends"
                  >
                  <i class='fa-solid fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/about/" title="关于"
                  
                  
                  
                    active-action="action-about"
                  >
                  <i class='fa-solid fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>
      
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fa-solid fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>
      

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fa-solid fa-search fa-fw" target="_self" href="/" onclick="return false;" title="search"></a></li>
				
				<li>
          <a class="s-menu fa-solid fa-bars fa-fw" target="_self" href="/" onclick="return false;" title="menu"></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/" title="博客"
                  
                  
                  
                    active-action="action-home"
                  >
                  <i class='fa-solid fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/categories/" title="分类"
                  
                  
                  
                    active-action="action-categories"
                  >
                  <i class='fa-solid fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/tags/" title="标签"
                  
                  
                  
                    active-action="action-tags"
                  >
                  <i class='fa-solid fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/archives/" title="归档"
                  
                  
                  
                    active-action="action-archives"
                  >
                  <i class='fa-solid fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/friends/" title="友链"
                  
                  
                  
                    active-action="action-friends"
                  >
                  <i class='fa-solid fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/about/" title="关于"
                  
                  
                  
                    active-action="action-about"
                  >
                  <i class='fa-solid fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>

      <!-- Custom Files header begin -->
      
      <!-- Custom Files header end -->
		</div>
	</div>
  </div>
</header>

    <div id="l_body">
      <div id="l_cover">
  
    
      <!-- see: /layout/_partial/scripts/_ctrl/coverCtrl.ejs -->
      <div id="none" class='cover-wrapper post search' style="display: none;">
        
  <div class='cover-bg lazyload placeholder' data-bg="https://tt-1316429231.cos.ap-nanjing.myqcloud.com/imgs/222.png"></div>

<div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">怒涛卷霜雪</p>
    
    
      <p class="subtitle">小博客</p>
    
  </div>
  <div class='bottom'>
    
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <input type="text" class="input u-search-input" placeholder="搜索一下" />
          <i class="icon fa-solid fa-search fa-fw"></i>
        </form>
      </div>
    
    <div class='menu navigation'>
      <div class='list-h'>
        
          
            <a href="/"
              
              
              active-action="action-home">
              <p>主页</p>
            </a>
          
            <a href="/faqs/"
              
              
              active-action="action-faqs">
              <p>帮助</p>
            </a>
          
            <a href="/tags/"
              
              
              active-action="action-tags">
              <p>标签</p>
            </a>
          
            <a href="/contributors/"
              
              
              active-action="action-contributors">
              <p>社区</p>
            </a>
          
            <a href="/archives/"
              
              
              active-action="action-archives">
              <p>博客</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

        <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
      </div>
    
  
</div>

      <div id="safearea">
        <div class="body-wrapper">
          
<div id="l_main" class=''>
  <article itemscope itemtype="http://schema.org/Article" class="article post white-box reveal md shadow floatable blur article-type-post" id="post" itemscope itemprop="blogPost">
  <link itemprop="mainEntityOfPage" href="http://breadwinners.top/2023/07/23/pytorch/RNN/">
  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="怒涛卷霜雪  天堑无涯">
  </span>
  <span hidden itemprop="post" itemscope itemtype="http://schema.org/Post">
    <meta itemprop="name" content="怒涛卷霜雪  天堑无涯">
    <meta itemprop="description" content="test description">
  </span>
  


  
    <span hidden>
      <meta itemprop="image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
    </span>
  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title" itemprop="name headline">
        RNN
      </h1>
      <div class='new-meta-box'>
        
          
            
  <div class='new-meta-item category'>
    <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
    <a class="category-link" href="/categories/pytorch/">pytorch</a>
    
      <span hidden itemprop="about" itemscope itemtype="http://schema.org/Thing">
        <a href="/categories/pytorch/" itemprop="url"><span itemprop="name">pytorch</span></a>
      </span>
    
  </div>


          
        
          
            <div class="new-meta-item date" itemprop="dateCreated datePublished" datetime="2023-07-23T00:00:00+08:00">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2023年7月23日</p>
  </a>
</div>

          
        
        <!-- Custom Files topMeta begin-->
        
        <!-- Custom Files topMeta end-->
      </div>
    
  </div>


  <div id="layoutHelper-page-plugins"></div>
  <div id="post-body" itemprop="articleBody">
    <h1 id="1-什么是RNN？"><a href="#1-什么是RNN？" class="headerlink" title="1 什么是RNN？"></a>1 什么是RNN？</h1><p>RNN是循环神经网络（Recurrent Neural Network）的缩写。它是一种神经网络结构，可以处理序列数据，例如时间序列数据或自然语言文本数据。相比于传统的前馈神经网络，RNN可以利用当前的输入和之前的状态来决定当前的输出，因此它可以捕捉到序列数据中的时间依赖关系。</p>
<p>在RNN中，每个时间步都有一个隐藏状态（hidden state），这个隐藏状态可以捕捉到之前时间步的信息，并且会在当前时间步中被用于计算输出。RNN的训练过程通常使用反向传播算法和梯度下降优化算法，目标是最小化模型预测值和真实值之间的误差。</p>
<p><strong>RNN在自然语言处理、语音识别、时间序列预测等领域都有广泛的应用</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/31df8177644126117057cbbefd6bcf11.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/31df8177644126117057cbbefd6bcf11.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423123352273"></p>
<h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1 原理"></a>1.1 原理</h2><p><strong>RNN的核心思想是利用当前的输入和之前的状态来决定当前的输出，这使得RNN可以处理序列数据中的时间依赖关系</strong>。RNN的结构可以看作是在时间轴上展开的多个神经网络层，每个时间步都有一个隐藏状态，这个隐藏状态可以传递到下一个时间步，并参与当前时间步的计算。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/5fbb8828d38c911dd9bdf446387ebf92.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/5fbb8828d38c911dd9bdf446387ebf92.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423123912734"></p>
<p>具体来说，RNN的计算可以分为三个步骤：</p>
<ol>
<li><strong>输入层和隐藏层之间的计算</strong>。假设当前时间步的输入是 x t x_t xt，上一个时间步的隐藏状态是 h t − 1 h_{t-1} ht−1，那么当前时间步的隐藏状态 h t h_t ht可以通过下面的公式计算得到：</li>
</ol>
<p>h t &#x3D; f ( W i h x t + b i h + W h h h t − 1 + b h h ) h_t &#x3D; f(W_{ih} x_t + b_{ih} + W_{hh} h_{t-1} + b_{hh}) ht=f(Wihxt+bih+Whhht−1+bhh)</p>
<p>其中 W i h W_{ih} Wih是输入层到隐藏层的权重矩阵， W h h W_{hh} Whh是隐藏层到隐藏层的权重矩阵， b i h b_{ih} bih和 b h h b_{hh} bhh是隐藏层的偏置向量， f f f是激活函数（通常是tanh或ReLU，上图中是tanh，即双曲正切函数）。</p>
<ol start="2">
<li><strong>隐藏层和输出层之间的计算</strong>。假设当前时间步的隐藏状态是 h t h_t ht，那么当前时间步的输出 y t y_t yt可以通过下面的公式计算得到：</li>
</ol>
<p>y t &#x3D; g ( W h y h t + b y ) y_t&#x3D;g(W_{hy}h_t+b_y) yt=g(Whyht+by)</p>
<p>其中 W h y W_{hy} Why是隐藏层到输出层的权重矩阵， b y b_y by是输出层的偏置向量， g g g是输出层的激活函数（通常是softmax）。</p>
<ol start="3">
<li><strong>损失函数计算和反向传播</strong>。根据任务类型，可以选择不同的损失函数，例如交叉熵损失函数用于分类任务，均方误差损失函数用于回归任务。然后使用反向传播算法和梯度下降优化算法来更新权重和偏置，目标是最小化模型预测值和真实值之间的误差。</li>
</ol>
<p>RNN的主要优点是可以处理任意长度的序列数据，并且可以捕捉序列数据中的时间依赖关系。然而，RNN也存在一些缺点，例如<strong>难以处理长期依赖关系、训练速度慢、梯度消失和梯度爆炸等问题</strong>。因此，研究人员提出了许多改进的RNN模型，例如LSTM和GRU等。</p>
<h2 id="1-2-维度说明"><a href="#1-2-维度说明" class="headerlink" title="1.2 维度说明"></a>1.2 维度说明</h2><p>在RNN中，输入、输出和隐藏层的维度可以根据具体的应用场景和数据集来确定。通常情况下，输入和输出的维度是固定的，而隐藏层的维度则是由用户自己指定的超参数。</p>
<p>以下是一些常见的维度配置：</p>
<ol>
<li>序列分类任务中，输入通常是一个序列的特征向量，输出是一个类别标签。假设输入序列的长度为<code>seq_len</code>，每个时间步的特征向量维度为<code>input_size</code>，输出类别数为<code>num_classes</code>，那么输入和输出的维度分别为<code>[batch_size, seq_len, input_size]</code>和<code>[batch_size, num_classes]</code>，其中<code>batch_size</code>为批次大小。</li>
<li>序列生成任务中，输入和输出都是一个序列。假设输入序列的长度为<code>seq_len</code>，每个时间步的特征向量维度为<code>input_size</code>，输出序列的长度也为<code>seq_len</code>，每个时间步的特征向量维度为<code>output_size</code>，那么输入和输出的维度都为<code>[batch_size, seq_len, input_size]</code>或<code>[batch_size, seq_len, output_size]</code>，具体要看是什么任务。</li>
<li>序列标注任务中，输入通常是一个序列的特征向量，输出是每个时间步的标注信息。假设输入序列的长度为<code>seq_len</code>，每个时间步的特征向量维度为<code>input_size</code>，输出标注类别数为<code>num_classes</code>，那么输入和输出的维度分别为<code>[batch_size, seq_len, input_size]</code>和<code>[batch_size, seq_len, num_classes]</code>。</li>
<li>在隐藏层维度方面，可以根据任务和数据集的复杂程度来选择合适的值。一般来说，隐藏层的维度越大，模型的表达能力就越强，但也会增加模型的计算复杂度和训练难度。通常情况下，隐藏层的维度在几十到几百之间。</li>
</ol>
<h1 id="2-一些琐碎代码"><a href="#2-一些琐碎代码" class="headerlink" title="2 一些琐碎代码"></a>2 一些琐碎代码</h1><h2 id="2-1-RNNCell"><a href="#2-1-RNNCell" class="headerlink" title="2.1 RNNCell"></a>2.1 RNNCell</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/6f191b1f04a6caaf2ff2eca9d455a9ff.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/6f191b1f04a6caaf2ff2eca9d455a9ff.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423130301157"></p>
<p>这段代码演示了如何使用PyTorch的<strong>RNNCell</strong>模块构建一个简单的RNN，并对一个简单的序列进行前向传递计算。</p>
<p>在代码中，我们首先构建了一个RNNCell对象，使用了输入维度为input_size、输出维度为hidden_size的隐藏层。接着，我们构造了一个大小为(seq_len, batch_size, input_size)的输入数据集dataset，并将隐藏状态hidden初始化为全零张量，大小为(batch_size, hidden_size)。</p>
<p>然后，我们将数据集按序列长度依次输入到RNNCell中，并在每一步更新隐藏状态hidden。在每一步中，我们打印出隐藏状态hidden的形状和值，以便了解RNN在每个时间步的输出情况。</p>
<p>具体来说，循环从seq_len的第0个时间步开始，依次将大小为(batch_size, input_size)的输入数据input输入到RNNCell中，并用当前的隐藏状态hidden计算下一个隐藏状态。由于这是一个简单的循环，每次更新隐藏状态时，输出的hidden大小保持不变，都是(batch_size, hidden_size)。</p>
<p><strong>代码如下：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Construction of RNNCell</span></span><br><span class="line">cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)</span><br><span class="line"><span class="comment"># Wrapping the sequence into:(seqLen,batchSize,InputSize)</span></span><br><span class="line">dataset = torch.randn(seq_len, batch_size, input_size)  <span class="comment"># (3,1,4)</span></span><br><span class="line"><span class="comment"># Initializing the hidden to zero</span></span><br><span class="line">hidden = torch.zeros(batch_size, hidden_size)  <span class="comment"># (1,2)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, <span class="built_in">input</span> <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">20</span>, idx, <span class="string">&#x27;=&#x27;</span> * <span class="number">20</span>)  <span class="comment">#分割线，20个=号</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Input size:&#x27;</span>, <span class="built_in">input</span>.shape)  <span class="comment"># (batch_size, input_size)</span></span><br><span class="line">    <span class="comment"># 按序列依次输入到cell中，seq_len=3，故循环3次</span></span><br><span class="line">    hidden = cell(<span class="built_in">input</span>, hidden)  <span class="comment"># 返回的hidden是下一次的输入之一，循环使用同一个cell</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;output size:&#x27;</span>, hidden.shape)  <span class="comment"># (batch_size, hidden_size)</span></span><br><span class="line">    <span class="built_in">print</span>(hidden)</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">==================== 0 ====================</span><br><span class="line">Input size: torch.Size([1, 4])</span><br><span class="line">output size: torch.Size([1, 2])</span><br><span class="line">tensor([[-0.4140,  0.1517]], grad_fn=&lt;TanhBackward0&gt;)</span><br><span class="line">==================== 1 ====================</span><br><span class="line">Input size: torch.Size([1, 4])</span><br><span class="line">output size: torch.Size([1, 2])</span><br><span class="line">tensor([[-0.4725, -0.7875]], grad_fn=&lt;TanhBackward0&gt;)</span><br><span class="line">==================== 2 ====================</span><br><span class="line">Input size: torch.Size([1, 4])</span><br><span class="line">output size: torch.Size([1, 2])</span><br><span class="line">tensor([[-0.8257, -0.2262]], grad_fn=&lt;TanhBackward0&gt;)</span><br></pre></td></tr></table></figure>

<p>可以看到，每次计算后的隐藏状态hidden都是2维的张量，大小为(batch_size, hidden_size) &#x3D; (1, 2)。在每个时间步骤中，输出的hidden值都不同，因为输入数据集dataset不同，而隐藏状态hidden是随着时间步骤的推进而更新的。</p>
<h2 id="2-2-RNN"><a href="#2-2-RNN" class="headerlink" title="2.2 RNN"></a>2.2 RNN</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/9f1e57ba1521fda37f18a802842ebdb3.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/9f1e57ba1521fda37f18a802842ebdb3.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423130925511"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b41b0739f8d6d9fc5ceeda96f31f9d15.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/b41b0739f8d6d9fc5ceeda96f31f9d15.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423132517785"></p>
<p>这段代码演示了如何使用PyTorch的<strong>RNN模块</strong>构建一个简单的RNN，并对一个简单的序列进行前向传递计算。</p>
<p>在这个例子中，我们首先构建了一个RNN对象，使用了输入维度为input_size、输出维度为hidden_size的隐藏层，并设置了RNN的层数num_layers为1（上图是num_layers为3的原理图，我们这里只使用了1层RNN）。接着，我们构造了一个大小为(seq_len, batch_size, input_size)的输入数据inputs，并将隐藏状态hidden初始化为全零张量，大小为(num_layers, batch_size, hidden_size)。</p>
<p>然后，我们<strong>将整个输入序列inputs输入到RNN中并得到输出output和最后一个时间步的隐藏状态hidden</strong>。在这个例子中，由于我们只有一个RNN层，因此hidden的大小与初始大小相同，仅仅是在第一维上添加了一个额外的维度。</p>
<p>最后，我们打印输出output和隐藏状态hidden的形状和值，以便了解RNN在整个序列上的输出情况。</p>
<p>具体来说，我们可以看到，整个输入序列的输出output是一个大小为(seq_len, batch_size, hidden_size) &#x3D; (3, 1, 2)的张量。其中，第一维表示序列长度，第二维表示批次大小，第三维表示隐藏层输出的维度。而最后一个时间步的隐藏状态hidden是一个大小为(num_layers, batch_size, hidden_size) &#x3D; (1, 1, 2)的张量。其中，第一维表示RNN的层数，第二维表示批次大小，第三维表示隐藏层输出的维度。</p>
<p><strong>代码如下：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line">num_layers = <span class="number">1</span>  <span class="comment"># RNN层数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Construction of RNN</span></span><br><span class="line">rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)</span><br><span class="line"><span class="comment"># Wrapping the sequence into:(seqLen,batchSize,InputSize)</span></span><br><span class="line">inputs = torch.randn(seq_len, batch_size, input_size)  <span class="comment"># (3,1,4)</span></span><br><span class="line"><span class="comment"># Initializing the hidden to zero</span></span><br><span class="line">hidden = torch.zeros(num_layers, batch_size, hidden_size)  <span class="comment"># (1,1,2)</span></span><br><span class="line"></span><br><span class="line">output, hidden = rnn(inputs, hidden)  <span class="comment"># RNN内部包含了循环，故这里只需把整个序列输入即可</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output size:&#x27;</span>, output.shape)  <span class="comment"># (seq_len, batch_size, hidden_size)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output:&#x27;</span>, output)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hidden size:&#x27;</span>, hidden.shape)  <span class="comment"># (num_layers, batch_size, hidden_size)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hidden:&#x27;</span>, hidden)</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Output size: torch.Size([3, 1, 2])</span><br><span class="line">Output: tensor([[[-0.9880, -0.8818]],</span><br><span class="line"></span><br><span class="line">        [[ 0.6066,  0.9090]],</span><br><span class="line"></span><br><span class="line">        [[-0.3108,  0.7957]]], grad_fn=&lt;StackBackward0&gt;)</span><br><span class="line">Hidden size: torch.Size([1, 1, 2])</span><br><span class="line">Hidden: tensor([[[-0.3108,  0.7957]]], grad_fn=&lt;StackBackward0&gt;)</span><br></pre></td></tr></table></figure>

<p>可以看到，输出output是一个3维的张量，大小为(seq_len, batch_size, hidden_size) &#x3D; (3, 1, 2)，在每个时间步的输出值都不同。最后一个时间步的隐藏状态hidden是一个3维的张量，大小为(num_layers, batch_size, hidden_size) &#x3D; (1, 1, 2)，是整个序列的最后一个时间步的隐藏状态。</p>
<p><strong>这个跟之前的RNNCell有什么不同呢？</strong></p>
<p>前面的例子中使用了<strong>RNNCell，它只是RNN的一个单元，用于处理一个时间步的输入数据，需要在循环中手动处理时间步</strong>。而在这个例子中，我们使用了<strong>完整的RNN模型，它内部包含了循环结构，可以一次性处理整个序列的输入，从而避免了手动处理时间步的繁琐过程</strong>。</p>
<p>在上面的代码中，我们使用torch.nn.RNN构造了一个RNN模型，并将整个序列inputs输入到模型中，模型内部完成了所有的循环计算，并返回了整个序列的输出output和最后一个时间步的隐状态hidden。值得注意的是，模型中的hidden状态是在不同的时间步共享的，即当前时间步的隐状态hidden是由上一个时间步的输出和隐状态计算得到的，这与前面的RNNCell是类似的。但是，完整的RNN模型会自动完成时间步之间的循环，因此更加方便。</p>
<h2 id="2-3-RNN参数：batch-first"><a href="#2-3-RNN参数：batch-first" class="headerlink" title="2.3 RNN参数：batch_first"></a>2.3 RNN参数：batch_first</h2><p>在PyTorch中，RNN模型的输入通常是(seq_len, batch_size, input_size)这样的形式，即时间步序列排列在第一维，批量数据排列在第二维。但是，在某些情况下，我们可能更倾向于使用(batch_size, seq_len, input_size)的输入形式。为了满足这种需要，PyTorch提供了batch_first参数。</p>
<p>当batch_first&#x3D;True时，输入和输出的形状就变成了(batch_size, seq_len, input_size)，这样就更符合一般的数据格式。在构造RNN模型时，只需将batch_first参数设置为True即可。</p>
<p>例如，对于一个RNN模型，当batch_first&#x3D;False时，输入的形状为(seq_len, batch_size, input_size)，而**当batch_first&#x3D;True时，输入的形状为(batch_size, seq_len, input_size)**。下面是一个示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line">num_layers = <span class="number">1</span>  <span class="comment"># RNN层数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Construction of RNN, batch_first=True</span></span><br><span class="line">rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 仅这里做了更改 Wrapping the sequence into:(batchSize,seqLen,InputSize)</span></span><br><span class="line">inputs = torch.randn(batch_size, seq_len, input_size)  <span class="comment"># (1,3,4)</span></span><br><span class="line"><span class="comment"># Initializing the hidden to zero</span></span><br><span class="line">hidden = torch.zeros(num_layers, batch_size, hidden_size)  <span class="comment"># (1,1,2)</span></span><br><span class="line"></span><br><span class="line">output, hidden = rnn(inputs, hidden)  <span class="comment"># RNN内部包含了循环，故这里只需把整个序列输入即可</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output size:&#x27;</span>, output.shape)  <span class="comment"># 输出维度发生变化(batch_size, seq_len, hidden_size)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output:&#x27;</span>, output)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hidden size:&#x27;</span>, hidden.shape)  <span class="comment"># (num_layers, batch_size, hidden_size)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hidden:&#x27;</span>, hidden)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Output size: torch.Size([1, 3, 2])</span><br><span class="line">Output: tensor([[[ 0.6276, -0.1454],</span><br><span class="line">         [ 0.0294,  0.3148],</span><br><span class="line">         [-0.3239,  0.4692]]], grad_fn=&lt;TransposeBackward1&gt;)</span><br><span class="line">Hidden size: torch.Size([1, 1, 2])</span><br><span class="line">Hidden: tensor([[[-0.3239,  0.4692]]], grad_fn=&lt;StackBackward0&gt;)</span><br></pre></td></tr></table></figure>

<p>在上面的例子中，我们构建了一个RNN模型，将batch_first参数设置为True，并将输入数据inputs的形状设置为(batch_size, seq_len, input_size)。通过这种方式，我们可以更方便地处理输入数据，而不用担心时间步和批量之间的顺序问题。</p>
<h1 id="3-例子：序列变换把-“hello”-–-gt-“ohlol”"><a href="#3-例子：序列变换把-“hello”-–-gt-“ohlol”" class="headerlink" title="3 例子：序列变换把 “hello” –&gt; “ohlol”"></a>3 例子：序列变换把 “hello” –&gt; “ohlol”</h1><p><img src="https://img-blog.csdnimg.cn/img_convert/588eb4afd1e358532a00217bef5ed1d1.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/588eb4afd1e358532a00217bef5ed1d1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423133037919"></p>
<h2 id="3-1-使用RNNCell"><a href="#3-1-使用RNNCell" class="headerlink" title="3.1 使用RNNCell"></a>3.1 使用RNNCell</h2><p><strong>输入的独热编码示意图：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/20624d03f7f3dba30e616cb0f55374b0.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/20624d03f7f3dba30e616cb0f55374b0.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423133230333"></p>
<p><strong>输出示意图：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/830949d8436ffd6fc91f143d343e21d7.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/830949d8436ffd6fc91f143d343e21d7.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423133401053"></p>
<p>这段代码是一个基于RNNCell的简单的字符级别的语言模型的训练过程。具体的训练过程如下：</p>
<ol>
<li>定义了一个大小为<code>input_size</code>的输入向量，大小为<code>hidden_size</code>的隐藏向量和批次大小为<code>batch_size</code>的<code>Model</code>类，并且在这个类的初始化函数中，构建了一个<code>RNNCell</code>。</li>
<li>使用给定的索引，将输入序列转换为 one-hot 向量，并将输入序列和标签序列都进行维度变换，使其变为 <code>(sequence_length, batch_size, input_size)</code> 和 <code>(sequence_length, 1)</code>。</li>
<li>定义损失函数为交叉熵损失函数，优化器为 Adam。</li>
<li>在循环训练的过程中，每次输入一个字符，即按序列次序进行循环。每次训练前先将优化器的梯度清零，然后使用 <code>net.init_hidden()</code> 初始化隐藏层，并在循环中使用 <code>net(input, hidden)</code> 得到下一个时间步的隐藏状态。接着计算损失，进行反向传播，更新参数。每次循环中还会打印出预测的字符和当前损失。</li>
<li>循环训练15次，直到训练完成。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、确定参数</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">4</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、准备数据</span></span><br><span class="line">index2char = [<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]  <span class="comment">#字典</span></span><br><span class="line">x_data = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]  <span class="comment">#用字典中的索引（数字）表示来表示hello</span></span><br><span class="line">y_data = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]  <span class="comment">#标签：ohlol</span></span><br><span class="line"></span><br><span class="line">one_hot_lookup = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],  <span class="comment"># 用来将x_data转换为one-hot向量的参照表</span></span><br><span class="line">                  [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">x_one_hot = [one_hot_lookup[x] <span class="keyword">for</span> x <span class="keyword">in</span> x_data]  <span class="comment">#将x_data转换为one-hot向量</span></span><br><span class="line">inputs = torch.Tensor(x_one_hot).view(-<span class="number">1</span>, batch_size, input_size)  <span class="comment">#(𝒔𝒆𝒒𝑳𝒆𝒏,𝒃𝒂𝒕𝒄𝒉𝑺𝒊𝒛𝒆,𝒊𝒏𝒑𝒖𝒕𝑺𝒊𝒛𝒆)</span></span><br><span class="line">labels = torch.LongTensor(y_data).view(-<span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># (seqLen*batchSize,𝟏).计算交叉熵损失时标签不需要我们进行one-hot编码，其内部会自动进行处理</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、构建模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, batch_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span><br><span class="line">        hidden = self.rnncell(<span class="built_in">input</span>, hidden)</span><br><span class="line">        <span class="keyword">return</span> hidden</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):  <span class="comment">#初始化隐藏层，需要batch_size</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(self.batch_size, self.hidden_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Model(input_size, hidden_size, batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、损失和优化器</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">0.1</span>)  <span class="comment"># Adam优化器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    optimizer.zero_grad()  <span class="comment">#梯度清零</span></span><br><span class="line">    hidden = net.init_hidden()  <span class="comment"># 初始化隐藏层</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted string:&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, label <span class="keyword">in</span> <span class="built_in">zip</span>(inputs, labels):  <span class="comment">#每次输入一个字符，即按序列次序进行循环</span></span><br><span class="line">        hidden = net(<span class="built_in">input</span>, hidden)</span><br><span class="line">        loss += criterion(hidden, label)  <span class="comment"># 计算损失，不用item()，因为后面还要反向传播</span></span><br><span class="line">        _, idx = hidden.<span class="built_in">max</span>(dim=<span class="number">1</span>)  <span class="comment"># 选取最大值的索引</span></span><br><span class="line">        <span class="built_in">print</span>(index2char[idx.item()], end=<span class="string">&#x27;&#x27;</span>)  <span class="comment"># 打印预测的字符</span></span><br><span class="line">    loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;, Epoch [%d/15] loss: %.4f&#x27;</span> % (epoch + <span class="number">1</span>, loss.item()))</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Predicted string:hehee, Epoch [1/15] loss: 8.2711</span><br><span class="line">Predicted string:olhll, Epoch [2/15] loss: 6.2931</span><br><span class="line">Predicted string:ollll, Epoch [3/15] loss: 5.3395</span><br><span class="line">Predicted string:ollll, Epoch [4/15] loss: 4.7223</span><br><span class="line">Predicted string:ohlll, Epoch [5/15] loss: 4.2614</span><br><span class="line">Predicted string:ohlll, Epoch [6/15] loss: 3.9137</span><br><span class="line">Predicted string:ohlol, Epoch [7/15] loss: 3.6579</span><br><span class="line">Predicted string:ohlol, Epoch [8/15] loss: 3.4601</span><br><span class="line">Predicted string:ohlol, Epoch [9/15] loss: 3.2896</span><br><span class="line">Predicted string:ohlol, Epoch [10/15] loss: 3.1306</span><br><span class="line">Predicted string:ohlol, Epoch [11/15] loss: 2.9806</span><br><span class="line">Predicted string:ohlol, Epoch [12/15] loss: 2.8476</span><br><span class="line">Predicted string:ohlol, Epoch [13/15] loss: 2.7450</span><br><span class="line">Predicted string:ohlol, Epoch [14/15] loss: 2.6792</span><br><span class="line">Predicted string:ohlol, Epoch [15/15] loss: 2.6347</span><br></pre></td></tr></table></figure>

<h2 id="3-2-使用RNN"><a href="#3-2-使用RNN" class="headerlink" title="3.2 使用RNN"></a>3.2 使用RNN</h2><p>在代码中，首先定义了一个RNN模型的类<code>Model</code>，继承自<code>torch.nn.Module</code>。这个模型接受一个<code>input_size</code>表示输入的向量维度，一个<code>hidden_size</code>表示隐藏层的向量维度，一个<code>batch_size</code>表示每批次输入数据的样本数量，以及一个可选的<code>num_layers</code>表示RNN的层数。</p>
<p>在这个类中，定义了一个RNN层<code>self.rnn</code>，输入为<code>input_size</code>和<code>hidden_size</code>，并指定层数为<code>num_layers</code>。在前向传播过程中，将输入数据<code>input</code>和一个全零张量<code>hidden</code>输入到RNN层中，然后将输出张量<code>out</code>从三维张量转换为二维张量，并返回输出张量。</p>
<p>在训练时，首先将优化器的梯度清零，然后将输入数据<code>inputs</code>送入模型中得到输出<code>outputs</code>。将输出<code>outputs</code>和标签<code>labels</code>输入到交叉熵损失函数中计算损失，然后通过反向传播计算梯度，并调用优化器的<code>step</code>方法更新模型参数。</p>
<p>最后，将输出<code>outputs</code>中每个时间步的预测结果取出来，转换为对应的字符，打印出来。同时，输出当前的损失和训练轮数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、确定参数</span></span><br><span class="line">seq_len = <span class="number">5</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">4</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、准备数据</span></span><br><span class="line">index2char = [<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]  <span class="comment">#字典</span></span><br><span class="line">x_data = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]  <span class="comment">#用字典中的索引（数字）表示来表示hello</span></span><br><span class="line">y_data = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]  <span class="comment">#标签：ohlol</span></span><br><span class="line"></span><br><span class="line">one_hot_lookup = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],  <span class="comment"># 用来将x_data转换为one-hot向量的参照表</span></span><br><span class="line">                  [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">x_one_hot = [one_hot_lookup[x] <span class="keyword">for</span> x <span class="keyword">in</span> x_data]  <span class="comment">#将x_data转换为one-hot向量</span></span><br><span class="line">inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size,</span><br><span class="line">                                      input_size)  <span class="comment">#(𝒔𝒆𝒒𝑳𝒆𝒏,𝒃𝒂𝒕𝒄𝒉𝑺𝒊𝒛𝒆,𝒊𝒏𝒑𝒖𝒕𝑺𝒊𝒛𝒆)</span></span><br><span class="line">labels = torch.LongTensor(y_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、构建模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, batch_size, num_layers=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.rnn = torch.nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)</span><br><span class="line">        out, _ = self.rnn(<span class="built_in">input</span>, hidden)  <span class="comment"># out: tensor of shape (seq_len, batch, hidden_size)</span></span><br><span class="line">        <span class="keyword">return</span> out.view(-<span class="number">1</span>, self.hidden_size)  <span class="comment"># 将输出的三维张量转换为二维张量,(𝒔𝒆𝒒𝑳𝒆𝒏×𝒃𝒂𝒕𝒄𝒉𝑺𝒊𝒛𝒆,𝒉𝒊𝒅𝒅𝒆𝒏𝑺𝒊𝒛𝒆)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):  <span class="comment">#初始化隐藏层，需要batch_size</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(self.batch_size, self.hidden_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Model(input_size, hidden_size, batch_size, num_layers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、损失和优化器</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">0.05</span>)  <span class="comment"># Adam优化器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs = net(inputs)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    _, idx = outputs.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">    idx = idx.data.numpy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted string: &#x27;</span>, <span class="string">&#x27;&#x27;</span>.join([index2char[x] <span class="keyword">for</span> x <span class="keyword">in</span> idx]), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;, Epoch [%d/15] loss: %.4f&#x27;</span> % (epoch + <span class="number">1</span>, loss.item()))</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Predicted string:  hhhhh, Epoch [1/15] loss: 1.4325</span><br><span class="line">Predicted string:  hhhhh, Epoch [2/15] loss: 1.2532</span><br><span class="line">Predicted string:  ohhoh, Epoch [3/15] loss: 1.1057</span><br><span class="line">Predicted string:  ohlol, Epoch [4/15] loss: 0.9970</span><br><span class="line">Predicted string:  ohlol, Epoch [5/15] loss: 0.9208</span><br><span class="line">Predicted string:  oolol, Epoch [6/15] loss: 0.8669</span><br><span class="line">Predicted string:  oolol, Epoch [7/15] loss: 0.8250</span><br><span class="line">Predicted string:  oolol, Epoch [8/15] loss: 0.7863</span><br><span class="line">Predicted string:  oolol, Epoch [9/15] loss: 0.7453</span><br><span class="line">Predicted string:  oolol, Epoch [10/15] loss: 0.7024</span><br><span class="line">Predicted string:  oolol, Epoch [11/15] loss: 0.6625</span><br><span class="line">Predicted string:  oolol, Epoch [12/15] loss: 0.6291</span><br><span class="line">Predicted string:  ohlol, Epoch [13/15] loss: 0.6026</span><br><span class="line">Predicted string:  ohlol, Epoch [14/15] loss: 0.5812</span><br><span class="line">Predicted string:  ohlol, Epoch [15/15] loss: 0.5630</span><br></pre></td></tr></table></figure>

<p>在这段代码中，<code>labels</code>不需要进行<code>.view(-1, 1)</code>处理的原因是因为它是一个一维的<code>LongTensor</code>张量，形状为<code>(seq_len,)</code>。在 PyTorch 的交叉熵损失函数 <code>torch.nn.CrossEntropyLoss()</code> 中，标签需要被表示成一维的长整型张量。这是因为交叉熵损失函数在内部将标签进行了one-hot编码，并使用这些编码来计算预测值和标签之间的损失。</p>
<p>在这段代码中，由于 <code>labels</code> 是一个一维张量，因此无需进行形状变换。当然，如果你将 <code>labels</code> 转换为 <code>(seq_len, 1)</code> 的形状也可以，但是在这种情况下，<code>torch.nn.CrossEntropyLoss()</code> 会自动将其转换回一维张量，所以不必进行此操作。</p>
<h2 id="3-3-使用embedding-and-linear-layer"><a href="#3-3-使用embedding-and-linear-layer" class="headerlink" title="3.3 使用embedding and linear layer"></a>3.3 使用embedding and linear layer</h2><p>在使用独热编码作为RNN输入时，有以下几个缺点：</p>
<ol>
<li>维度灾难：对于大规模的数据集和多类分类问题，独热编码会导致输入数据维度极度膨胀，从而导致模型参数变得非常庞大，训练和推理时间变慢。</li>
<li>数据稀疏性：独热编码会使得大部分输入都是0，因为只有一个位置是1，这导致输入数据非常稀疏，浪费了大量的存储空间和计算资源。</li>
<li>无法表达序列信息：在RNN中，序列的顺序很重要，但是独热编码无法表达序列信息，只能表达每个输入在类别上的差异。因此，在处理序列数据时，独热编码可能无法捕捉到序列中的模式和规律。</li>
<li>无法处理未知类别：独热编码需要预先知道类别的数量，如果遇到新的类别，需要重新扩展编码向量，这会带来额外的开销和复杂度。</li>
</ol>
<p>因此，在某些情况下，可以考虑使用其他的编码方式来解决这些问题，例如使用<strong>嵌入（embedding）向量</strong>来表示输入数据，或者使用特征哈希（feature hashing）等技术来降低维度。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/3eafc8c0cc0acca2a060af889807e30f.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/3eafc8c0cc0acca2a060af889807e30f.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423135726064"></p>
<h3 id="嵌入（embedding）向量"><a href="#嵌入（embedding）向量" class="headerlink" title="嵌入（embedding）向量"></a>嵌入（embedding）向量</h3><p>嵌入（embedding）向量是一种将离散型数据（如词语、用户ID等）映射到连续型向量空间中的技术，常用于自然语言处理、推荐系统等领域。</p>
<p><strong>嵌入向量的原理是利用神经网络中的一层或多层进行映射</strong>。假设有n个离散化的元素，每个元素用一个唯一的整数进行编码。嵌入层的输入是这些编码，输出是每个编码对应的k维嵌入向量，通常k的值会远小于n，因此将数据从一个大的高维空间压缩到一个较小的低维空间。</p>
<p>在嵌入层中，每个元素的编码都被映射为一个固定长度的向量，且不同元素的向量之间可以计算相似度，这个相似度在一定程度上反映了它们在原始数据中的关系。例如，在自然语言处理中，相似的单词（如“cat”和“dog”）在嵌入空间中的向量会更加接近，因为它们在语义上有一定的相关性。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/dbe19f704f5918d7e9be11a3f7e31733.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/dbe19f704f5918d7e9be11a3f7e31733.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423140105849"></p>
<p>嵌入向量在许多应用中被广泛使用，例如语言模型、情感分析、推荐系统等。在自然语言处理中，通过使用嵌入向量可以将文本转换为数字，从而方便机器学习算法处理。同时，由于嵌入向量的低维度表示，计算速度较快，可以处理大规模数据集。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2cd06fd4da6e07435b3add9f758bfa89.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/2cd06fd4da6e07435b3add9f758bfa89.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423140241004"></p>
<h3 id="相关函数"><a href="#相关函数" class="headerlink" title="相关函数"></a>相关函数</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/0c678249a8a2aa75abf0d1fdd6b4fd5f.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/0c678249a8a2aa75abf0d1fdd6b4fd5f.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423141828128"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/413481db7d2e90152753d5620acba5f7.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/413481db7d2e90152753d5620acba5f7.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423141848208"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9d813d83fc4c7ede582b8a128b8c7823.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/9d813d83fc4c7ede582b8a128b8c7823.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423141912482"></p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>这段代码是一个基于RNN的字符级别的语言模型，用于预测给定输入字符序列的下一个字符。下面是对代码的解释和说明：</p>
<ol>
<li>在确定参数的部分，定义了RNN的输入和输出大小、隐藏状态的维度、Embedding向量的大小、RNN层数等参数，这些参数将会在模型的构建中使用。</li>
<li>在准备数据的部分，定义了一个字典<code>index2char</code>用于将数字索引映射到字符，输入数据<code>x_data</code>是一段英文字符串”hello”，并将其转换为数字索引的形式。</li>
<li>在构建模型的部分，使用了PyTorch中的<code>Embedding</code>层将输入字符的数字索引转换为固定长度的向量表示，该向量表示将在RNN中传递。使用<code>RNN</code>层将Embedding向量作为输入，计算RNN的输出。最后，通过一个全连接层<code>fc</code>将RNN的输出映射到每个字符的概率分布。在这个模型中，全连接层的作用是对RNN的输出做一个线性变换，从而将输出的维度从隐藏状态的维度变为每个字符的数量。</li>
<li>在定义损失函数和优化器的部分，使用了交叉熵损失函数作为模型的损失函数，Adam优化器来更新模型的参数。</li>
<li>在训练模型的部分，使用一个简单的循环进行模型的训练，每次训练输出当前训练次数和损失值，并打印出模型预测的字符串。在这个过程中，每个字符的Embedding向量会随着训练不断调整，最终使模型能够对字符序列做出准确的预测。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、确定参数</span></span><br><span class="line">num_class = <span class="number">4</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">8</span></span><br><span class="line">embedding_size = <span class="number">10</span></span><br><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、准备数据</span></span><br><span class="line">index2char = [<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]  <span class="comment">#字典</span></span><br><span class="line">x_data = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># (batch_size, seq_len) 用字典中的索引（数字）表示来表示hello</span></span><br><span class="line">y_data = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]  <span class="comment">#  (batch_size * seq_len) 标签：ohlol</span></span><br><span class="line"></span><br><span class="line">inputs = torch.LongTensor(x_data)  <span class="comment"># (batch_size, seq_len)</span></span><br><span class="line">labels = torch.LongTensor(y_data)  <span class="comment"># (batch_size * seq_len)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、构建模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.emb = torch.nn.Embedding(num_class, embedding_size)</span><br><span class="line">        self.rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers,</span><br><span class="line">                                batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(hidden_size, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        hidden = torch.zeros(num_layers, x.size(<span class="number">0</span>), hidden_size)  <span class="comment"># (num_layers, batch_size, hidden_size)</span></span><br><span class="line">        x = self.emb(x)  <span class="comment"># 返回(batch_size, seq_len, embedding_size)</span></span><br><span class="line">        x, _ = self.rnn(x, hidden)  <span class="comment"># 返回(batch_size, seq_len, hidden_size)</span></span><br><span class="line">        x = self.fc(x)  <span class="comment"># 返回(batch_size, seq_len, num_class)</span></span><br><span class="line">        <span class="keyword">return</span> x.view(-<span class="number">1</span>, num_class)  <span class="comment"># (batch_size * seq_len, num_class)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、损失和优化器</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">0.05</span>)  <span class="comment"># Adam优化器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs = net(inputs)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    _, idx = outputs.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">    idx = idx.data.numpy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted string: &#x27;</span>, <span class="string">&#x27;&#x27;</span>.join([index2char[x] <span class="keyword">for</span> x <span class="keyword">in</span> idx]), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;, Epoch [%d/15] loss: %.4f&#x27;</span> % (epoch + <span class="number">1</span>, loss.item()))</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Predicted string:  eeeee, Epoch [1/15] loss: 1.5407</span><br><span class="line">Predicted string:  oolol, Epoch [2/15] loss: 1.1158</span><br><span class="line">Predicted string:  oolol, Epoch [3/15] loss: 0.9047</span><br><span class="line">Predicted string:  ohlol, Epoch [4/15] loss: 0.7391</span><br><span class="line">Predicted string:  lhlol, Epoch [5/15] loss: 0.6006</span><br><span class="line">Predicted string:  ohlol, Epoch [6/15] loss: 0.4833</span><br><span class="line">Predicted string:  ohlol, Epoch [7/15] loss: 0.3581</span><br><span class="line">Predicted string:  ohlol, Epoch [8/15] loss: 0.2540</span><br><span class="line">Predicted string:  ohlol, Epoch [9/15] loss: 0.1921</span><br><span class="line">Predicted string:  ohlol, Epoch [10/15] loss: 0.1351</span><br><span class="line">Predicted string:  ohlol, Epoch [11/15] loss: 0.0972</span><br><span class="line">Predicted string:  ohlol, Epoch [12/15] loss: 0.0752</span><br><span class="line">Predicted string:  ohlol, Epoch [13/15] loss: 0.0594</span><br><span class="line">Predicted string:  ohlol, Epoch [14/15] loss: 0.0465</span><br><span class="line">Predicted string:  ohlol, Epoch [15/15] loss: 0.0363</span><br></pre></td></tr></table></figure>

<h1 id="4-LSTM和GRU"><a href="#4-LSTM和GRU" class="headerlink" title="4 LSTM和GRU"></a>4 LSTM和GRU</h1><p>上面 RNN 模型也存在一些局限性：</p>
<ol>
<li><p><strong>梯度消失和梯度爆炸问题</strong>：当序列非常长时，梯度可能会逐渐消失或爆炸，导致网络无法学习长序列的依赖关系。</p>
</li>
<li><p><strong>只能学习固定长度的序列</strong>：由于 RNN 的输入和输出都是固定长度的，因此模型只能学习固定长度的序列。</p>
</li>
<li><p><strong>处理不同时间步的输入时存在数据对齐问题</strong>：在训练 RNN 时，需要将不同长度的序列对齐到相同的长度，这通常需要一些预处理和后处理，而且可能会导致信息丢失或噪声引入。</p>
</li>
<li><p><strong>无法很好地处理长期依赖关系</strong>：尽管 RNN 可以学习一定的序列依赖性，但是当序列的时间跨度很大时，RNN 可能会出现长期依赖问题。此外，由于 RNN 的循环结构，每个时间步的输出都依赖于前一时间步的状态，因此模型可能会受到某些时间步的信息干扰。</p>
</li>
</ol>
<p>有几种方法可以尝试解决RNN模型的一些局限性：</p>
<ol>
<li><strong>使用更高级别的模型</strong>：可以使用一些更先进的模型，<strong>如LSTM（长短期记忆网络）和GRU（门控循环单元）等</strong>，这些模型在一定程度上解决了RNN模型存在的一些问题。</li>
<li><strong>添加注意力机制</strong>：注意力机制可以帮助模型在输入序列中关注不同的部分，并对重要的部分进行加权，从而提高模型的准确性。</li>
<li><strong>使用更多的数据</strong>：增加数据量可以帮助模型更好地学习输入序列的规律，从而提高模型的准确性。</li>
<li><strong>对数据进行预处理</strong>：对输入数据进行预处理，如归一化、降噪、平滑等，可以提高模型的鲁棒性和准确性。</li>
<li><strong>结合其他技术</strong>：可以结合其他技术来解决模型存在的问题，如集成学习、正则化、Dropout等。</li>
</ol>
<p>LSTM（Long Short-Term Memory，长短期记忆网络）和GRU（Gated Recurrent Unit，门控循环单元）是常用的循环神经网络（RNN）的变种，相比于传统的RNN，它们能够更好地处理长序列数据，解决了传统RNN中的梯度消失和梯度爆炸问题。</p>
<p>LSTM的主要思想是引入一个称为“细胞状态”（cell state）的记忆单元，以及三个门（输入门、遗忘门和输出门）来控制对细胞状态的访问和更新。其中，输入门决定了新的输入如何影响细胞状态，遗忘门决定了何时忘记旧的细胞状态，输出门决定了输出什么样的信息。LSTM的结构相对复杂，需要较高的计算资源和训练时间。</p>
<p>GRU是由Cho等人于2014年提出的一种轻量级的门控循环单元，它只包含两个门（更新门和重置门），通过控制输入和历史状态的权重来控制信息流动。GRU的结构比LSTM简单，计算量也相对较小，同时在处理长序列数据时也具有不错的效果。</p>
<p>总的来说，LSTM和GRU是目前在循环神经网络领域中表现优异的模型，但具体选择哪种模型需要根据具体的任务和数据集来决定。</p>
<ul>
<li><p><strong>LSTM原理示意图</strong></p>
<p>  相关链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/v_JULY_v/article/details/89894058">如何从RNN起步，一步一步通俗理解LSTM</a></p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/aa23cdf08be5160d13f10f359460ec2a.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/aa23cdf08be5160d13f10f359460ec2a.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423142703707"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/57f2458163206f6272a1d3570a94d2fc.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/57f2458163206f6272a1d3570a94d2fc.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423142740832"></p>
<ul>
<li><p><strong>GRU原理示意图</strong></p>
<p>  相关链接：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32481747">人人都能看懂的GRU</a></p>
<p>  <img src="https://img-blog.csdnimg.cn/img_convert/1e9e6ad841ee0634c729936585643939.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/1e9e6ad841ee0634c729936585643939.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423142842256"></p>
<p>  <img src="https://img-blog.csdnimg.cn/img_convert/1cda4a9e497792bf7ca97e2b6136cb9f.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/img_convert/1cda4a9e497792bf7ca97e2b6136cb9f.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image-20230423142911736"></p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_56676945/article/details/130321316">原文地址</a></p>

  </div>
  
  
    
    <div class='footer'>
       <!-- 参考资料、相关资料等 -->
      
       <!-- 相关文章 -->
      
      <!-- 版权声明组件 -->
      
      <!-- 打赏组件 -->
      
    </div>
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateModified" datetime="2023-08-01T09:46:54+08:00">
  <a class='notlink'>
    <i class="fa-solid fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2023年8月1日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/rnn/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>rnn</p></a></div>
  <span hidden itemprop="keywords">rnn</span>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://breadwinners.top/2023/07/23/pytorch/RNN/&title=RNN - 怒涛卷霜雪  天堑无涯&summary="
          
          >
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qq.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qq.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://breadwinners.top/2023/07/23/pytorch/RNN/&title=RNN - 怒涛卷霜雪  天堑无涯&summary="
          
          >
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qzone.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qzone.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://service.weibo.com/share/share.php?url=http://breadwinners.top/2023/07/23/pytorch/RNN/&title=RNN - 怒涛卷霜雪  天堑无涯&summary="
          
          >
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/weibo.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/weibo.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
    
      
    
  </div>
</div>



        
      
    </div>
    <!-- Custom Files bottomMeta begin -->
    
    <!-- Custom Files bottomMeta end -->
  </div>


  
  

  
    <div class="prev-next">
      
        <a class='prev' href='/2023/07/23/pytorch/RNN%E9%9A%90%E8%97%8F%E5%B1%82/'>
          <p class='title'><i class="fa-solid fa-chevron-left" aria-hidden="true"></i>RNN中的隐层</p>
          <p class='content'>RNN(循环神经网络)中的隐层可以理解为RNN单元之间传递信息的通道。具体来说:

RNN由多个相同的RNN单元堆叠组成,每个RNN单元都包含输入、隐层和输出。
隐层记录当前时刻RNN单元的状态...</p>
        </a>
      
      
        <a class='next' href='/2023/07/22/pytorch/pytorch%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/'>
          <p class='title'>pytorch卷积神经网络基础<i class="fa-solid fa-chevron-right" aria-hidden="true"></i></p>
          <p class='content'>说明 0、前一部分叫做Feature Extraction，后一部分叫做classification
​    1、每一个卷积核它的通道数量要求和输入通道是一样的。这种卷积核的总数有多少个和你输...</p>
        </a>
      
    </div>
  
  <!-- Custom Files postEnd begin-->
  
  <!-- Custom Files postEnd end-->
</article>


  


  <article class="post white-box shadow floatable blur" id="comments">
    <span hidden>
      <meta itemprop="discussionUrl" content="/2023/07/23/pytorch/RNN/index.html#comments">
    </span>
    <p ct><i class='fa-solid fa-comments'></i> 评论</p>
    

    <div id="layoutHelper-comments"></div>

  </article>






</div>
<aside id='l_side' itemscope itemtype="http://schema.org/WPSideBar">
  

  
    
    
      
    
  


<div class="widget-sticky pjax">

  
  


  <section class="widget toc-wrapper desktop mobile " id="toc-div" >
    
  <header>
    
      <i class="fa-solid fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%8E%9F%E7%90%86"><span class="toc-text">1.1 原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E7%BB%B4%E5%BA%A6%E8%AF%B4%E6%98%8E"><span class="toc-text">1.2 维度说明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-RNNCell"><span class="toc-text">2.1 RNNCell</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-RNN"><span class="toc-text">2.2 RNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-RNN%E5%8F%82%E6%95%B0%EF%BC%9Abatch-first"><span class="toc-text">2.3 RNN参数：batch_first</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E4%BD%BF%E7%94%A8RNNCell"><span class="toc-text">3.1 使用RNNCell</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E4%BD%BF%E7%94%A8RNN"><span class="toc-text">3.2 使用RNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-%E4%BD%BF%E7%94%A8embedding-and-linear-layer"><span class="toc-text">3.3 使用embedding and linear layer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%EF%BC%88embedding%EF%BC%89%E5%90%91%E9%87%8F"><span class="toc-text">嵌入（embedding）向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0"><span class="toc-text">相关函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-text">代码</span></a></li></ol></li></ol>
    </div>
  </section>

  

</div>


<!-- 没有 pjax 占位会报错 万恶的 pjax -->

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <!-- Custom Files side begin -->
  
  <!-- Custom Files side end -->
</aside>



          <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<pjax>
<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  pdata.commentConfig={};
  //  see: /layout/_partial/scripts/_ctrl/coverCtrl.ejs
  
    // header
    var l_header=document.getElementById("l_header");
    
    l_header.classList.add("show");
    
    
      // cover
      var cover_wrapper=document.querySelector('#l_cover .cover-wrapper');
      var scroll_down=document.getElementById('scroll-down');
      cover_wrapper.id="none";
      cover_wrapper.style.display="none";
      scroll_down.style.display="none";
    
  
</script>
</pjax>
        </div>
        
  
  <footer class="footer clearfix"  itemscope itemtype="http://schema.org/WPFooter">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper" itemprop="about" itemscope itemtype="http://schema.org/Thing">
          
            
              <a href="/atom.xml"
                class="social fas fa-rss flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
            
              <a href="mailto:wutao222666@163.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
            
              <a href="https://github.com/breadwinnert"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        本站使用
        <a href="https://github.com/volantis-x/hexo-theme-volantis/#5.7.10" target="_blank" class="codename">Volantis</a>
        作为主题
      
    
      
        <div class='copyright'>
        <p><a href="/">Copyright © 2017-2023 breadwinners</a></p>

        </div>
      
    
    <!-- Custom Files footer begin-->
    
        <img src="http://www.gov.cn/images/gtrs_logo_lt.png" class="lazyload" data-srcset="http://www.gov.cn/images/gtrs_logo_lt.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="15px">
    <a href="https://beian.miit.gov.cn/"  style="color:#f72b07" target="_blank">湘ICP备2023012514号</a>
    <!-- Custom Files footer end-->
  </footer>


        <a id="s-top" class="fa-solid fa-arrow-up fa-fw" href="/" onclick="return false;" title="top"></a>
      </div>
    </div>
    <div>
      <script>
  /******************** volantis.dom ********************************/
  // 页面选择器 将dom对象缓存起来 see: /source/js/app.js etc.
  volantis.dom.bodyAnchor = volantis.dom.$(document.getElementById("safearea")); // 页面主体
  volantis.dom.topBtn = volantis.dom.$(document.getElementById('s-top')); // 向上
  volantis.dom.wrapper = volantis.dom.$(document.getElementById('wrapper')); // 整个导航栏
  volantis.dom.coverAnchor = volantis.dom.$(document.querySelector('#l_cover .cover-wrapper')); // 1个
  volantis.dom.switcher = volantis.dom.$(document.querySelector('#l_header .switcher .s-search')); // 搜索按钮   移动端 1个
  volantis.dom.header = volantis.dom.$(document.getElementById('l_header')); // 移动端导航栏
  volantis.dom.search = volantis.dom.$(document.querySelector('#l_header .m_search')); // 搜索框 桌面端 移动端 1个
  volantis.dom.mPhoneList = volantis.dom.$(document.querySelectorAll('#l_header .m-phone .list-v')); //  手机端 子菜单 多个
</script>

<script>
  
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fortawesome/fontawesome-free/css/all.min.css");
  
  
  
</script>

<!-- required -->


<!-- internal -->

<script src="/js/app.js"></script>






<!-- rightmenu要在darkmode之前（ToggleButton） darkmode要在comments之前（volantis.dark.push）-->



<script>
  function loadIssuesJS() {
    
      const sites_api = document.getElementById('sites-api');
      if (sites_api != undefined && typeof SitesJS === 'undefined') {
        volantis.js("/js/plugins/tags/sites.js")
      }
    
    
      const friends_api = document.getElementById('friends-api');
      if (friends_api != undefined && typeof FriendsJS === 'undefined') {
        volantis.js("/js/plugins/tags/friends.js")
      }
    
    
      const contributors_api = document.getElementById('contributors-api');
      if (contributors_api != undefined && typeof ContributorsJS === 'undefined') {
        volantis.js("/js/plugins/tags/contributors.js")
      }
    
  };
  loadIssuesJS()
  volantis.pjax.push(()=>{
    loadIssuesJS();
  })

</script>




  <script defer src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/vanilla-lazyload/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: ["#"],
	maxRPS: 6,
	hoverDelay: 0
  };
</script>
<script defer src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/flying-pages/flying-pages.min.js"></script>









      <script>
  volantis.layoutHelper("comments",`<div id="giscus_container"></div>`)

  volantis.giscus = {};

  function check_giscus() {
    if (volantis.dark.mode === "dark") {
      volantis.giscus.Theme = 'dark';
    } else {
      volantis.giscus.Theme = 'light';
    }

    return document.getElementById("giscus_container");
  }

  function pjax_giscus() {
    const HEAD = check_giscus();
    if (!HEAD) return;
    let cfg = Object.assign({"theme":{"light":"light","dark":"dark"},"repo":"breadwinnert/myBlogComments","repo-id":"R_kgDOJdFfnw","category":"Announcements","category-id":"DIC_kwDOJdFfn84CWJ2W","mapping":"pathname","reactions-enabled":"1","emit-metadata":"0","lang":"zh-CN"},pdata.commentConfig)
    const script = document.createElement('script');
    script.setAttribute('src', 'https://giscus.app/client.js');
    Object.keys(cfg).forEach(k=>{
      if (k != "theme") {
        script.setAttribute('data-'+k, cfg[k]);
      }
    })
    script.setAttribute('data-theme', volantis.giscus.Theme);
    script.setAttribute('crossorigin', "anonymous");
    HEAD.appendChild(script);
  }

  function dark_giscus() {
    const HEAD = check_giscus();
    if (!HEAD) return;

    const message = {
      setConfig: {
        theme: volantis.giscus.Theme
      }
    };
    const giscusIframe = document.querySelector('iframe.giscus-frame');
    giscusIframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
  }
  pjax_giscus();
  volantis.pjax.push(pjax_giscus);
  volantis.dark.push(dark_giscus);
</script>

    





<!-- optional -->

  <script>
  const SearchServiceDataPathRoot = ("/" || "/").endsWith("/") ?
    "/" || "/" :
    "//" || "/";
  const SearchServiceDataPath = SearchServiceDataPathRoot + "content.json";

  function loadSearchScript() {
    // see: layout/_partial/scripts/_ctrl/cdnCtrl.ejs
    return volantis.js("/js/search/hexo.js");
  }

  function loadSearchService() {
    loadSearchScript();
    document.querySelectorAll(".input.u-search-input").forEach((e) => {
      e.removeEventListener("focus", loadSearchService, false);
    });

    document.querySelectorAll(".u-search-form").forEach((e) => {
      e.addEventListener("submit", (event) => {
        event.preventDefault();
      }, false);
    });
  }

  // 打开并搜索 字符串 s
  function OpenSearch(s) {
    if (typeof SearchService === 'undefined')
      loadSearchScript().then(() => {
        SearchService.setQueryText(s);
        SearchService.search();
      });
    else {
      SearchService.setQueryText(s);
      SearchService.search();
    }
  }

  // 访问含有 ?s=xxx  的链接时打开搜索 // 与搜索引擎 structured data 相关: /scripts/helpers/structured-data/lib/config.js
  if (window.location.search && /^\?s=/g.test(window.location.search)) {
    let queryText = decodeURI(window.location.search)
      .replace(/\ /g, "-")
      .replace(/^\?s=/g, "");
    OpenSearch(queryText);
  }

  // 搜索输入框获取焦点时加载搜索
  document.querySelectorAll(".input.u-search-input").forEach((e) => {
    e.addEventListener("focus", loadSearchService, false);
  });
</script>







  <script>



  function pjax_highlightjs_copyCode(){
    if (!(document.querySelector(".highlight .code pre") ||
      document.querySelector(".article pre code"))) {
      return;
    }
    VolantisApp.utilCopyCode(".highlight .code pre, .article pre code")
  }
  volantis.requestAnimationFrame(pjax_highlightjs_copyCode)
  volantis.pjax.push(pjax_highlightjs_copyCode)

</script>












  <script>
  function load_swiper() {
    if (!document.querySelectorAll(".swiper-container")[0]) return;
    volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/swiper/swiper-bundle.min.css");
    volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/swiper/swiper-bundle.min.js").then(() => {
      pjax_swiper();
    });
  }

  load_swiper();

  function pjax_swiper() {
    volantis.swiper = new Swiper('.swiper-container', {
      slidesPerView: 'auto',
      spaceBetween: 8,
      centeredSlides: true,
      loop: true,
      pagination: {
        el: '.swiper-pagination',
        clickable: true,
      },
      navigation: {
        nextEl: '.swiper-button-next',
        prevEl: '.swiper-button-prev',
      },
    });
  }

  volantis.pjax.push(() => {
    if (!document.querySelectorAll(".swiper-container")[0]) return;
    if (typeof volantis.swiper === "undefined") {
      load_swiper();
    } else {
      pjax_swiper();
    }
  });
</script>


<!-- pjax 标签必须存在于所有页面 否则 pjax error -->
<pjax>

</pjax>

<script>
  function listennSidebarTOC() {
    const navItems = document.querySelectorAll(".toc li");
    if (!navItems.length) return;
    let targets = []
    const sections = [...navItems].map((element) => {
      const link = element.querySelector(".toc-link");
      const target = document.getElementById(
        decodeURI(link.getAttribute("href")).replace("#", "")
      );
      targets.push(target)
      // 解除 a 标签 href 的 锚点定位, a 标签 href 的 锚点定位 会随机启用?? 产生错位???
      link.setAttribute("onclick","return false;")
      link.setAttribute("toc-action","toc-"+decodeURI(link.getAttribute("href")).replace("#", ""))
      link.setAttribute("href","/")
      // 配置 点击 触发新的锚点定位
      link.addEventListener("click", (event) => {
        event.preventDefault();
        // 这里的 addTop 是通过错位使得 toc 自动展开.
        volantis.scroll.to(target,{addTop: 5, observer:true})
        // Anchor id
        history.pushState(null, document.title, "#" + target.id);
      });
      return target;
    });

    function activateNavByIndex(target) {
      if (target.classList.contains("active-current")) return;

      document.querySelectorAll(".toc .active").forEach((element) => {
        element.classList.remove("active", "active-current");
      });
      target.classList.add("active", "active-current");
      let parent = target.parentNode;
      while (!parent.matches(".toc")) {
        if (parent.matches("li")) parent.classList.add("active");
        parent = parent.parentNode;
      }
    }

    // 方案一：
    volantis.activateNavIndex=0
    activateNavByIndex(navItems[volantis.activateNavIndex])
    volantis.scroll.push(()=>{
      if (targets[0].getBoundingClientRect().top >= 0) {
        volantis.activateNavIndex = 0
      }else if (targets[targets.length-1].getBoundingClientRect().top < 0) {
        volantis.activateNavIndex = targets.length-1
      } else {
        for (let index = 0; index < targets.length; index++) {
          const target0 = targets[index];
          const target1 = targets[(index+1)%targets.length];
          if (target0.getBoundingClientRect().top < 0&&target1.getBoundingClientRect().top >= 0) {
            volantis.activateNavIndex=index
            break;
          }
        }
      }
      activateNavByIndex(navItems[volantis.activateNavIndex])
    })

    // 方案二：
    // IntersectionObserver 不是完美精确到像素级别 也不是低延时性的
    // function findIndex(entries) {
    //   let index = 0;
    //   let entry = entries[index];
    //   if (entry.boundingClientRect.top > 0) {
    //     index = sections.indexOf(entry.target);
    //     return index === 0 ? 0 : index - 1;
    //   }
    //   for (; index < entries.length; index++) {
    //     if (entries[index].boundingClientRect.top <= 0) {
    //       entry = entries[index];
    //     } else {
    //       return sections.indexOf(entry.target);
    //     }
    //   }
    //   return sections.indexOf(entry.target);
    // }
    // function createIntersectionObserver(marginTop) {
    //   marginTop = Math.floor(marginTop + 10000);
    //   let intersectionObserver = new IntersectionObserver(
    //     (entries, observe) => {
    //       let scrollHeight = document.documentElement.scrollHeight;
    //       if (scrollHeight > marginTop) {
    //         observe.disconnect();
    //         createIntersectionObserver(scrollHeight);
    //         return;
    //       }
    //       let index = findIndex(entries);
    //       activateNavByIndex(navItems[index]);
    //     }, {
    //       rootMargin: marginTop + "px 0px -100% 0px",
    //       threshold: 0,
    //     }
    //   );
    //   sections.forEach((element) => {
    //     element && intersectionObserver.observe(element);
    //   });
    // }
    // createIntersectionObserver(document.documentElement.scrollHeight);
  }

  document.addEventListener("DOMContentLoaded", ()=>{
    volantis.requestAnimationFrame(listennSidebarTOC)
  });
  document.addEventListener("pjax:success", ()=>{
    volantis.requestAnimationFrame(listennSidebarTOC)
  });
</script>



<script>
  document.onreadystatechange = function () {
    if (document.readyState == 'complete') {
      // 页面加载完毕 样式加载失败，或是当前网速慢，或是开启了省流模式
      const { saveData, effectiveType } = navigator.connection || navigator.mozConnection || navigator.webkitConnection || {}
      if (getComputedStyle(document.querySelector("#safearea"), null)["display"] == "none" || saveData || /2g/.test(effectiveType)) {
        document.querySelectorAll(".reveal").forEach(function (e) {
          e.style["opacity"] = "1";
        });
        document.querySelector("#safearea").style["display"] = "block";
      }
    }
  }
</script>


  <script type="application/ld+json">[{"@context":"http://schema.org","@type":"Organization","name":"怒涛卷霜雪  天堑无涯","url":"http://breadwinners.top/","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},{"@context":"http://schema.org","@type":"Person","name":"吴涛","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"http://breadwinners.top/","sameAs":["https://github.com/volantis-x"],"description":"test description"},{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"http://breadwinners.top/","name":"怒涛卷霜雪  天堑无涯"}},{"@type":"ListItem","position":2,"item":{"@id":"http://breadwinners.top/categories/pytorch/","name":"pytorch"}},{"@type":"ListItem","position":3,"item":{"@id":"http://breadwinners.top/2023/07/23/pytorch/RNN/","name":"RNN"}}]},{"@context":"http://schema.org","@type":"WebSite","name":"怒涛卷霜雪  天堑无涯","url":"http://breadwinners.top/","keywords":null,"description":"test description","author":{"@type":"Person","name":"吴涛","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"http://breadwinners.top/","description":"test description"},"publisher":{"@type":"Organization","name":"怒涛卷霜雪  天堑无涯","url":"http://breadwinners.top/","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},"potentialAction":{"@type":"SearchAction","name":"Site Search","target":{"@type":"EntryPoint","urlTemplate":"http://breadwinners.top?s={search_term_string}"},"query-input":"required name=search_term_string"}},{"@context":"http://schema.org","@type":"BlogPosting","headline":"RNN","description":"test description","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"http://breadwinners.top/2023/07/23/pytorch/RNN/"},"author":{"@type":"Person","name":"吴涛","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"http://breadwinners.top/"},"publisher":{"@type":"Organization","name":"怒涛卷霜雪  天堑无涯","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},"url":"http://breadwinners.top/2023/07/23/pytorch/RNN/","wordCount":0,"datePublished":"2023-07-22T16:00:00.000Z","dateModified":"2023-08-01T01:46:54.757Z","articleSection":"pytorch","keywords":"rnn","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}}]</script>



      
        <!--
  pjax重载区域接口：
  1.  <pjax></pjax> 标签 pjax 标签必须存在于所有页面 否则 pjax error
  2.  script[data-pjax]
  3.  .pjax-reload script
  4.  .pjax
-->



<script src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/pjax/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox]):not([onclick="return false;"]):not([onclick="return!1"]):not([target="_blank"]):not([target="view_window"]):not([href$=".xml"])',
        selectors: [
          "head title",
          "head meta[name=keywords]",
          "head meta[name=description]",
          
          "#l_main",
          "#pjax-header-nav-list",
          ".pjax",
          "pjax", // <pjax></pjax> 标签
          "script[data-pjax], .pjax-reload script" // script标签添加data-pjax 或 script标签外层添加.pjax-reload 的script代码段重载
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000,
        
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
      volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      // 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
      volantis.pjax.method.complete.start();
    });

    document.addEventListener('pjax:error', function (e) {
      if(volantis.debug) {
        console.error(e);
        console.log('pjax error: \n' + JSON.stringify(e));
      }else{
        // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
        volantis.pjax.method.error.start();
        window.location.href = e.triggerElement.href;
      }
    });
</script>

      
    </div>
    <!-- import body_end begin-->
    <!-- import body_end end-->
    <!-- Custom Files bodyEnd begin-->
    
    <!-- Custom Files bodyEnd end-->
  </body>
</html>
